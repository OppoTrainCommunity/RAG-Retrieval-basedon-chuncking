# CV-Based Career Path Recommendation System â€“ Retrieval Component

## ğŸ“‹ Overview

RAG system that analyzes resumes/CVs and extracts relevant information using semantic search. The workflow: **Read PDF** â†’ **Chunk text** â†’ **Embed** â†’ **Store in ChromaDB** â†’ **Query semantically** â†’ **Retrieve results**.

---

## ğŸ”§ Installation

### Prerequisites
- **Python** 3.8+
- **pip**

### Setup

```bash
pip install chromadb sentence-transformers pymupdf nltk
python -c "import nltk; nltk.download('punkt')"
```

### Folder Structure

```
Retrieval_Task/
â”œâ”€â”€ retrieval.ipynb
â”œâ”€â”€ questions.txt (one question per line)
â”œâ”€â”€ cvs/ (place your PDF files here)
â””â”€â”€ README.md
```

---

## ğŸ“Š Chunking Methods (4 Strategies)

| Method | Granularity | Speed | Best For | Trade-offs |
|--------|------------|-------|----------|-----------|
| **1. Sentence-based** | Medium | Fast | QA systems | Variable chunk sizes |
| **2. Paragraph-based** | Coarse | Very Fast | Structured docs | Large variable sizes |
| **3. Semantic (Fixed Window)** | Fine | Fast | General purpose | May split sentences |
| **4. Sliding Window** | Fine | Fast | Production â­ | Best all-around |

**Recommended:** Use **Sliding Window (Method 4)** for production and **Semantic (Method 3)** for development.

---

## ğŸ§  Embedding Models (3 Options)

| Model | Dimensions | Speed | Accuracy | Memory | Best For |
|-------|-----------|-------|----------|--------|----------|
| **all-MiniLM-L6-v2** | 384 | â­â­â­â­â­ | â­â­â­ | Minimal | Real-time apps |
| **all-mpnet-base-v2** | 768 | â­â­â­ | â­â­â­â­ | ~220 MB | Balanced |
| **paraphrase-mpnet-base-v2** | 768 | â­â­â­ | â­â­â­â­â­ | ~220 MB | High accuracy â­ |

**Recommended:** Use **paraphrase-mpnet-base-v2** for production quality, **all-MiniLM-L6-v2** for speed.

---

## ğŸš€ Quick Start

1. Run notebook: `jupyter notebook retrieval.ipynb`
2. Choose chunking method (recommend: Sliding Window)
3. Choose embedding model (recommend: paraphrase-mpnet-base-v2)
4. View results with similarity scores

**Example Output:**
```
ğŸ” Query: What are my technical skills?
â­ Result #1 | Similarity: 0.8234 | [Relevant excerpt...]
â­ Result #2 | Similarity: 0.7891 | [Related content...]
```

---

## ğŸ” How It Works

```
PDF â†’ Chunk Text â†’ Embed â†’ Store in ChromaDB â†’ Query â†’ Retrieve Top-K Results
```

**Cosine Similarity:** Measures relevance (0 = different, 1 = identical)

---

## ğŸ’¡ Recommendations

**Production:** Sliding Window chunking + paraphrase-mpnet-base-v2 + top 3-5 results  
**Development:** Semantic chunking + all-MiniLM-L6-v2 + top 3 results  
**High Accuracy:** Sentence-based chunking + paraphrase-mpnet-base-v2


---

## ğŸ› Troubleshooting

| Issue | Solution |
|-------|----------|
| `ModuleNotFoundError: sentence_transformers` | `pip install sentence-transformers` |
| `FileNotFoundError: cvs` | Create `cvs/` folder and add PDF files |
| `FileNotFoundError: questions.txt` | Create `questions.txt` with queries (one per line) |
| Keras version error | `pip install tf-keras` or set `os.environ["TRANSFORMERS_NO_TF"] = "1"` |

---

## ğŸ“š Next Steps

1. **LLM Integration** - Use retrieved chunks as context for generation
2. **UI Development** - Build Streamlit/Gradio interface
3. **Production Deploy** - Docker + API endpoints + persistent database




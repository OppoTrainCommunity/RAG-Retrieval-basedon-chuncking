{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7970f2a8",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "257ddb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements (uncomment if needed)\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "345cd9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Standard libraries imported\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n",
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "print(\"‚úÖ Standard libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83c904d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Configuration loaded:\n",
      "   LLM Model: mistralai/mistral-7b-instruct:free\n",
      "   Judge Model: mistralai/mistral-7b-instruct:free\n",
      "   Embeddings Provider: openrouter\n",
      "   Embeddings Model: openai/text-embedding-3-small\n",
      "   Chroma Collection: cv_rag\n",
      "   Top-K: 6\n",
      "   API Key Set: ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "from src.config import load_config, get_config\n",
    "\n",
    "# Load config from yaml and environment\n",
    "config = load_config(\"config.yaml\")\n",
    "\n",
    "print(\"üìã Configuration loaded:\")\n",
    "print(f\"   LLM Model: {config.llm.model}\")\n",
    "print(f\"   Judge Model: {config.judge.model}\")\n",
    "print(f\"   Embeddings Provider: {config.embeddings.provider}\")\n",
    "print(f\"   Embeddings Model: {config.embeddings.model}\")\n",
    "print(f\"   Chroma Collection: {config.chroma.collection}\")\n",
    "print(f\"   Top-K: {config.retrieval.top_k}\")\n",
    "print(f\"   API Key Set: {'‚úÖ' if config.openrouter_api_key else '‚ùå'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14bb70d",
   "metadata": {},
   "source": [
    "## 2. Load CV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb94324a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ Loaded 5 CVs\n",
      "   Columns: ['candidate_id', 'name', 'email', 'role', 'location', 'years_experience', 'raw_text']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>name</th>\n",
       "      <th>role</th>\n",
       "      <th>location</th>\n",
       "      <th>years_experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV001</td>\n",
       "      <td>Alice Johnson</td>\n",
       "      <td>Senior Software Engineer</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CV002</td>\n",
       "      <td>Bob Martinez</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CV003</td>\n",
       "      <td>Carol Chen</td>\n",
       "      <td>Product Manager</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CV004</td>\n",
       "      <td>David Kim</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV005</td>\n",
       "      <td>Emma Wilson</td>\n",
       "      <td>UX Designer</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  candidate_id           name                      role           location  \\\n",
       "0        CV001  Alice Johnson  Senior Software Engineer  San Francisco, CA   \n",
       "1        CV002   Bob Martinez            Data Scientist       New York, NY   \n",
       "2        CV003     Carol Chen           Product Manager        Seattle, WA   \n",
       "3        CV004      David Kim           DevOps Engineer         Austin, TX   \n",
       "4        CV005    Emma Wilson               UX Designer    Los Angeles, CA   \n",
       "\n",
       "   years_experience  \n",
       "0                 8  \n",
       "1                 5  \n",
       "2                 6  \n",
       "3                 7  \n",
       "4                 4  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data.loaders import load_cvs, create_sample_cv_data, save_sample_data\n",
    "\n",
    "# Check if sample data exists, create if not\n",
    "cvs_path = Path(config.data.cvs_path)\n",
    "if not cvs_path.exists():\n",
    "    print(\"üìù Creating sample CV data...\")\n",
    "    save_sample_data(str(cvs_path))\n",
    "\n",
    "# Load CVs\n",
    "df_cvs = load_cvs(str(cvs_path))\n",
    "\n",
    "print(f\"\\nüìÑ Loaded {len(df_cvs)} CVs\")\n",
    "print(f\"   Columns: {list(df_cvs.columns)}\")\n",
    "df_cvs[[\"candidate_id\", \"name\", \"role\", \"location\", \"years_experience\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb0fc4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Sample CV: Alice Johnson (Senior Software Engineer)\n",
      "============================================================\n",
      "\n",
      "ALICE JOHNSON\n",
      "Senior Software Engineer | San Francisco, CA\n",
      "alice.johnson@email.com | (555) 123-4567 | linkedin.com/in/alicejohnson\n",
      "\n",
      "SUMMARY\n",
      "Experienced software engineer with 8+ years of expertise in building scalable web applications and distributed systems. Strong background in Python, JavaScript, and cloud technologies. Passionate about clean code and mentoring junior developers.\n",
      "\n",
      "EXPERIENCE\n",
      "\n",
      "Senior Software Engineer | TechCorp Inc. | 2020 - Present\n",
      "- Led development of microservices architecture serving 10M+ daily users\n",
      "- Implemented CI/CD pipelines reducing deployment time by 60%\n",
      "- Mentored team of 5 junior developers\n",
      "- Technologies: Python, FastAPI, Kubernetes, AWS, PostgreSQL\n",
      "\n",
      "Software Engineer | StartupXYZ | 2017 - 2020\n",
      "- Built real-time data processing pipeline handling 1M events/hour\n",
      "- Developed RESTful APIs for mobile and web clients\n",
      "- Reduced infrastructure costs by 40% through optimization\n",
      "- Technologies: Python, Django, Redis, Docker, GCP\n",
      "\n",
      "Junior Developer | WebAgency | 2015 - 2017\n",
      "- Developed responsive web applications for various clients\n",
      "- Created automated testing suites improving code quality\n",
      "- Technologies: JavaScript, React, Node.js, MongoDB\n",
      "\n",
      "EDUCATION\n",
      "Master of Science in Computer Science | Stanford University | 2015\n",
      "Bachelor of Science in Computer Science | UC Berkeley | 2013\n",
      "\n",
      "SKILLS\n",
      "Programming: Python, JavaScript, TypeScript, Go, SQL\n",
      "Frameworks: FastAPI, Django, React, Node.js, Express\n",
      "Cloud & DevOps: AWS, GCP, Kuber...\n"
     ]
    }
   ],
   "source": [
    "# Preview a CV\n",
    "sample_cv = df_cvs.iloc[0]\n",
    "print(f\"üìã Sample CV: {sample_cv['name']} ({sample_cv['role']})\")\n",
    "print(\"=\" * 60)\n",
    "print(sample_cv['raw_text'][:1500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d42e6f6",
   "metadata": {},
   "source": [
    "## 3. Semantic Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cc9fc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÇÔ∏è Created 7 chunks from 5 CVs\n",
      "   Average chunks per CV: 1.4\n"
     ]
    }
   ],
   "source": [
    "from src.data.chunking import CVChunker, chunk_dataframe, save_chunks\n",
    "\n",
    "# Create chunker\n",
    "chunker = CVChunker(\n",
    "    split_experience_roles=True,\n",
    "    min_chunk_length=50,\n",
    "    max_chunk_length=2000,\n",
    ")\n",
    "\n",
    "# Chunk all CVs\n",
    "chunks_df = chunk_dataframe(\n",
    "    df_cvs,\n",
    "    candidate_id_col=\"candidate_id\",\n",
    "    text_col=\"raw_text\",\n",
    "    chunker=chunker,\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÇÔ∏è Created {len(chunks_df)} chunks from {len(df_cvs)} CVs\")\n",
    "print(f\"   Average chunks per CV: {len(chunks_df) / len(df_cvs):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "480bcaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Chunks by Section:\n",
      "   header: 6\n",
      "   publications: 1\n"
     ]
    }
   ],
   "source": [
    "# View chunk distribution by section\n",
    "section_counts = chunks_df['section_name'].value_counts()\n",
    "print(\"üìä Chunks by Section:\")\n",
    "for section, count in section_counts.items():\n",
    "    print(f\"   {section}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef1aa7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>section_name</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>768757522e20</td>\n",
       "      <td>CV001</td>\n",
       "      <td>header</td>\n",
       "      <td>Alice Johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fa63c002a8f3</td>\n",
       "      <td>CV002</td>\n",
       "      <td>header</td>\n",
       "      <td>Bob Martinez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18978d8b92ed</td>\n",
       "      <td>CV003</td>\n",
       "      <td>header</td>\n",
       "      <td>Carol Chen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>800bef25d6bf</td>\n",
       "      <td>CV004</td>\n",
       "      <td>header</td>\n",
       "      <td>David Kim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eb97eaa3ef4a</td>\n",
       "      <td>CV005</td>\n",
       "      <td>header</td>\n",
       "      <td>Emma Wilson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9ca77c4b0f08</td>\n",
       "      <td>CV005</td>\n",
       "      <td>publications</td>\n",
       "      <td>Emma Wilson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>75660f5aa874</td>\n",
       "      <td>CV005</td>\n",
       "      <td>header</td>\n",
       "      <td>Emma Wilson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       chunk_id candidate_id  section_name           name\n",
       "0  768757522e20        CV001        header  Alice Johnson\n",
       "1  fa63c002a8f3        CV002        header   Bob Martinez\n",
       "2  18978d8b92ed        CV003        header     Carol Chen\n",
       "3  800bef25d6bf        CV004        header      David Kim\n",
       "4  eb97eaa3ef4a        CV005        header    Emma Wilson\n",
       "5  9ca77c4b0f08        CV005  publications    Emma Wilson\n",
       "6  75660f5aa874        CV005        header    Emma Wilson"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview chunks\n",
    "display_cols = ['chunk_id', 'candidate_id', 'section_name', 'name']\n",
    "existing_cols = [c for c in display_cols if c in chunks_df.columns]\n",
    "chunks_df[existing_cols].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bdd7940b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved chunks to data\\processed\\chunks.parquet\n"
     ]
    }
   ],
   "source": [
    "# Save chunks (optional)\n",
    "chunks_path = Path(config.data.chunks_path)\n",
    "chunks_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "save_chunks(chunks_df, str(chunks_path))\n",
    "print(f\"üíæ Saved chunks to {chunks_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6cb8b9",
   "metadata": {},
   "source": [
    "## 4. Embeddings & Build Chroma Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a458f34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî§ Creating embeddings with provider: openrouter\n",
      "‚úÖ Embeddings initialized\n"
     ]
    }
   ],
   "source": [
    "from src.embeddings.factory import EmbeddingsFactory\n",
    "from src.vectordb.chroma_store import ChromaStore\n",
    "from src.utils.timing import Timer\n",
    "\n",
    "# Create embeddings\n",
    "print(f\"üî§ Creating embeddings with provider: {config.embeddings.provider}\")\n",
    "embeddings = EmbeddingsFactory.from_config(config)\n",
    "print(\"‚úÖ Embeddings initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "854faff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loaded existing index with 24 documents\n"
     ]
    }
   ],
   "source": [
    "# Create Chroma store\n",
    "chroma_store = ChromaStore(\n",
    "    persist_dir=config.chroma.persist_dir,\n",
    "    collection_name=config.chroma.collection,\n",
    "    embeddings=embeddings,\n",
    ")\n",
    "\n",
    "# Check if index already exists\n",
    "if chroma_store.load_index():\n",
    "    print(f\"üìÇ Loaded existing index with {chroma_store.document_count} documents\")\n",
    "else:\n",
    "    print(\"üî® Building new index...\")\n",
    "    with Timer(\"Index build\") as timer:\n",
    "        chroma_store.build_index(\n",
    "            chunks_df,\n",
    "            text_col=\"chunk_text\",\n",
    "            id_col=\"chunk_id\",\n",
    "        )\n",
    "    print(f\"‚úÖ Built index with {chroma_store.document_count} documents in {timer.elapsed:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd75fafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Test Query: 'Python developer with AWS experience'\n",
      "\n",
      "Top 3 Results:\n",
      "\n",
      "1. Score: 1.1174\n",
      "   Candidate: CV004\n",
      "   Section: header\n",
      "   Preview: DAVID KIM\n",
      "DevOps Engineer | Austin, TX\n",
      "david.kim@email.com | (555) 321-0987 | github.com/davidkim\n",
      "\n",
      "PROFILE\n",
      "DevOps engineer with 7 years of experi...\n",
      "\n",
      "2. Score: 1.1436\n",
      "   Candidate: CV001\n",
      "   Section: header\n",
      "   Preview: ALICE JOHNSON\n",
      "Senior Software Engineer | San Francisco, CA\n",
      "alice.johnson@email.com | (555) 123-4567 | linkedin.com/in/alicejohnson\n",
      "\n",
      "SUMMARY\n",
      "Exper...\n",
      "\n",
      "3. Score: 1.3727\n",
      "   Candidate: CV002\n",
      "   Section: header\n",
      "   Preview: BOB MARTINEZ\n",
      "Data Scientist | New York, NY\n",
      "bob.martinez@email.com | (555) 987-6543 | github.com/bobmartinez\n",
      "\n",
      "PROFILE\n",
      "Data Scientist with 5 years ...\n"
     ]
    }
   ],
   "source": [
    "# Test retrieval\n",
    "test_query = \"Python developer with AWS experience\"\n",
    "results = chroma_store.similarity_search_with_score(test_query, k=3)\n",
    "\n",
    "print(f\"üîç Test Query: '{test_query}'\")\n",
    "print(\"\\nTop 3 Results:\")\n",
    "for i, (doc, score) in enumerate(results, 1):\n",
    "    print(f\"\\n{i}. Score: {score:.4f}\")\n",
    "    print(f\"   Candidate: {doc.metadata.get('candidate_id')}\")\n",
    "    print(f\"   Section: {doc.metadata.get('section_name')}\")\n",
    "    print(f\"   Preview: {doc.page_content[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34292c9",
   "metadata": {},
   "source": [
    "## 5. Query Demo (Single Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c1c81b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó RAG Chain initialized\n",
      "   Model: mistralai/mistral-7b-instruct:free\n",
      "   Top-K: 6\n"
     ]
    }
   ],
   "source": [
    "from src.rag.chain import RAGChain\n",
    "\n",
    "# Create RAG chain\n",
    "rag_chain = RAGChain.from_config(config, chroma_store)\n",
    "print(\"üîó RAG Chain initialized\")\n",
    "print(f\"   Model: {config.llm.model}\")\n",
    "print(f\"   Top-K: {config.retrieval.top_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "251bd41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload templates to pick up fix\n",
    "import importlib\n",
    "import src.prompts.templates\n",
    "importlib.reload(src.prompts.templates)\n",
    "from src.prompts.templates import get_rag_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6600f792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì Query: Who has the most experience with Kubernetes and what are their qualifications?\n",
      "======================================================================\n",
      "\n",
      "üìù Answer:\n",
      " The candidate with the most experience with Kubernetes is David Kim. Here are his qualifications and experience with Kubernetes:\n",
      "\n",
      "- **Experience**:\n",
      "  - Architected multi-region Kubernetes infrastructure handling 50K RPS [Candidate: CV004, Section: experience]\n",
      "  - Built CI/CD pipelines for 50+ microservices [Candidate: CV004, Section: experience]\n",
      "  - Technologies: Kubernetes, Terraform, AWS, Prometheus, Grafana [Candidate: CV004, Section: experience]\n",
      "\n",
      "- **Certifications**:\n",
      "  - Certified Kubernetes Administrator (CKA) [Candidate: CV004, Section: certifications]\n",
      "  - Certified Kubernetes Security Specialist (CKS) [Candidate: CV004, Section: certifications]\n",
      "\n",
      "- **Skills**:\n",
      "  - Containers: Kubernetes, Docker, Helm, Istio [Candidate: CV004, Section: skills]\n",
      "\n",
      "- **Projects**:\n",
      "  - K8s Cost Optimizer - Open source tool for Kubernetes cost optimization [Candidate: CV004, Section: projects]\n",
      "\n",
      "Alice Johnson also has Kubernetes experience but less extensive than David Kim's:\n",
      "- **Experience**:\n",
      "  - Led development of microservices architecture serving 10M+ daily users [Candidate: CV001, Section: experience]\n",
      "  - Technologies: Python, FastAPI, Kubernetes, AWS, PostgreSQL [Candidate: CV001, Section: experience]\n",
      "\n",
      "- **Certifications**:\n",
      "  - Kubernetes Administrator (CKA) [Candidate: CV001, Section: certifications]\n",
      "\n",
      "- **Skills**:\n",
      "  - Cloud & DevOps: AWS, GCP, Kubernetes, Docker, Terraform, CI/CD [Candidate: CV001, Section: skills]\n",
      "\n",
      "David Kim's experience with Kubernetes is more comprehensive, including architecture, cost optimization, and security, as well as multiple certifications.\n",
      "\n",
      "‚è±Ô∏è Timing:\n",
      "   Retrieval: 1.484s\n",
      "   Generation: 9.427s\n",
      "   Total: 10.911s\n"
     ]
    }
   ],
   "source": [
    "# Single query demo\n",
    "query = \"Who has the most experience with Kubernetes and what are their qualifications?\"\n",
    "\n",
    "print(f\"‚ùì Query: {query}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "response = rag_chain.invoke(query)\n",
    "\n",
    "print(f\"\\nüìù Answer:\")\n",
    "print(response.answer)\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Timing:\")\n",
    "print(f\"   Retrieval: {response.retrieval_time:.3f}s\")\n",
    "print(f\"   Generation: {response.generation_time:.3f}s\")\n",
    "print(f\"   Total: {response.retrieval_time + response.generation_time:.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3f0a97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìö Sources (6 chunks retrieved):\n",
      "======================================================================\n",
      "\n",
      "[1] Candidate: CV004 | Section: header\n",
      "    Chunk ID: \n",
      "    Score: 0.8869\n",
      "    Content: DAVID KIM\n",
      "DevOps Engineer | Austin, TX\n",
      "david.kim@email.com | (555) 321-0987 | github.com/davidkim\n",
      "\n",
      "PROFILE\n",
      "DevOps engineer with 7 years of experience in cloud infrastructure, automation, and site...\n",
      "\n",
      "[2] Candidate: CV001 | Section: header\n",
      "    Chunk ID: \n",
      "    Score: 1.2565\n",
      "    Content: ALICE JOHNSON\n",
      "Senior Software Engineer | San Francisco, CA\n",
      "alice.johnson@email.com | (555) 123-4567 | linkedin.com/in/alicejohnson\n",
      "\n",
      "SUMMARY\n",
      "Experienced software engineer with 8+ years of expertis...\n",
      "\n",
      "[3] Candidate: CV002 | Section: header\n",
      "    Chunk ID: \n",
      "    Score: 1.2899\n",
      "    Content: BOB MARTINEZ\n",
      "Data Scientist | New York, NY\n",
      "bob.martinez@email.com | (555) 987-6543 | github.com/bobmartinez\n",
      "\n",
      "PROFILE\n",
      "Data Scientist with 5 years of experience in machine learning, statistical mod...\n",
      "\n",
      "[4] Candidate: CV003 | Section: header\n",
      "    Chunk ID: \n",
      "    Score: 1.3194\n",
      "    Content: CAROL CHEN\n",
      "Product Manager | Seattle, WA\n",
      "carol.chen@email.com | (555) 456-7890 | linkedin.com/in/carolchen\n",
      "\n",
      "SUMMARY\n",
      "Strategic product manager with 6 years of experience driving product developmen...\n",
      "\n",
      "[5] Candidate: CV005 | Section: header\n",
      "    Chunk ID: \n",
      "    Score: 1.3853\n",
      "    Content: CERTIFICATIONS\n",
      "- Google UX Design Certificate\n",
      "- Certified Usability Analyst (CUA)\n",
      "- Accessibility Specialist Certification\n",
      "\n",
      "AWARDS\n",
      "- Webby Award Honoree 2023 - Mobile App Design\n",
      "- AIGA Design A...\n",
      "\n",
      "[6] Candidate: CV005 | Section: publications\n",
      "    Chunk ID: \n",
      "    Score: 1.4763\n",
      "    Content: Research: User Interviews, Usability Testing, A/B Testing, Analytics\n",
      "Methods: Design Thinking, Jobs-to-be-Done, Accessibility (WCAG)\n",
      "Technical: HTML/CSS basics, Design Systems, Component Libraries...\n"
     ]
    }
   ],
   "source": [
    "# Display sources\n",
    "print(f\"\\nüìö Sources ({response.num_sources} chunks retrieved):\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, source in enumerate(response.sources, 1):\n",
    "    print(f\"\\n[{i}] Candidate: {source.candidate_id} | Section: {source.section_name}\")\n",
    "    print(f\"    Chunk ID: {source.chunk_id}\")\n",
    "    if source.score:\n",
    "        print(f\"    Score: {source.score:.4f}\")\n",
    "    print(f\"    Content: {source.content[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caf90fc",
   "metadata": {},
   "source": [
    "## 6. Batch Demo (Multiple Queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8d2a6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Running batch of 5 queries...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define test queries\n",
    "test_queries = [\n",
    "    \"Which candidates have experience with machine learning and NLP?\",\n",
    "    \"Find candidates with AWS certifications\",\n",
    "    \"Who has product management experience at enterprise companies?\",\n",
    "    \"Which designers have won awards for their work?\",\n",
    "    \"Compare the education backgrounds of all candidates\",\n",
    "]\n",
    "\n",
    "print(f\"üîÑ Running batch of {len(test_queries)} queries...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "815f6a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Query 1: Which candidates have experience with machine learning and NLP?\n",
      "======================================================================\n",
      "\n",
      " Based on the provided CVs, only Bob Martinez (CV002) has experience with machine learning and NLP.\n",
      "\n",
      "Relevant details from his CV:\n",
      "- \"Data Scientist with 5 years of experience in machine learning, statistical modeling, and data analysis. Expertise in NLP, computer vision, and recommendation systems.\" [Candidate: CV002, Section: header]\n",
      "- \"Developed NLP models for sentiment analysis achieving 94% accuracy\" [Candidate: CV002, Section: experience]\n",
      "- \"Built recommendation engine increasing user enga...\n",
      "\n",
      "‚è±Ô∏è Time: 4.40s | Sources: 6\n",
      "\n",
      "======================================================================\n",
      "Query 2: Find candidates with AWS certifications\n",
      "======================================================================\n",
      "\n",
      " Here are the candidates with AWS certifications:\n",
      "\n",
      "1. **David Kim** (CV004) - AWS Solutions Architect Professional [Candidate: CV004, Section: certifications]\n",
      "2. **Alice Johnson** (CV001) - AWS Solutions Architect Professional [Candidate: CV001, Section: certifications]\n",
      "3. **Bob Martinez** (CV002) - Uses AWS SageMaker and GCP AI Platform [Candidate: CV002, Section: skills]\n",
      "\n",
      "The context does not provide information about Carol Chen (CV003) or Emma Wilson (CV005) having AWS certifications.\n",
      "\n",
      "‚è±Ô∏è Time: 4.37s | Sources: 6\n",
      "\n",
      "======================================================================\n",
      "Query 3: Who has product management experience at enterprise companies?\n",
      "======================================================================\n",
      "\n",
      " Carol Chen has product management experience at enterprise companies. Here are the relevant details from her CV:\n",
      "\n",
      "- As a Senior Product Manager at CloudTech Solutions (2021 - Present), she \"Launched enterprise SaaS product generating $5M ARR in first year\" and \"Managed cross-functional team of 15 engineers, designers, and analysts\" [Candidate: CV003, Section: experience]\n",
      "- At InnovateCo (2019 - 2021), she \"Led mobile app redesign resulting in 4.8 star rating (up from 3.2)\" and \"Defined and exec...\n",
      "\n",
      "‚è±Ô∏è Time: 3.16s | Sources: 6\n",
      "\n",
      "======================================================================\n",
      "Query 4: Which designers have won awards for their work?\n",
      "======================================================================\n",
      "\n",
      " Emma Wilson has won awards for her work. She received the Webby Award Honoree 2023 for Mobile App Design and the AIGA Design Award 2022. [Candidate: CV005, Section: header]\n",
      "\n",
      "Bob Martinez also has awards in his background. He won the Best Paper Award at the Data Science Conference 2021 and the Innovation Award from DataDriven Corp in 2022. [Candidate: CV002, Section: header]\n",
      "\n",
      "The other candidates (Alice Johnson and Carol Chen) do not have any awards listed in their CVs.\n",
      "\n",
      "‚è±Ô∏è Time: 3.06s | Sources: 6\n",
      "\n",
      "======================================================================\n",
      "Query 5: Compare the education backgrounds of all candidates\n",
      "======================================================================\n",
      "\n",
      " Here's a comparison of the education backgrounds of all candidates based on the provided CVs:\n",
      "\n",
      "1. **Bob Martinez (CV002)**:\n",
      "   - PhD in Statistics (ABD) | Columbia University | 2018\n",
      "   - Master of Science in Applied Mathematics | NYU | 2016\n",
      "   - Bachelor of Science in Mathematics | MIT | 2014\n",
      "   [Candidate: CV002, Section: education]\n",
      "\n",
      "2. **David Kim (CV004)**:\n",
      "   - Bachelor of Science in Computer Engineering | UT Austin | 2016\n",
      "   [Candidate: CV004, Section: education]\n",
      "\n",
      "3. **Carol Chen (CV003)**...\n",
      "\n",
      "‚è±Ô∏è Time: 9.21s | Sources: 6\n"
     ]
    }
   ],
   "source": [
    "# Run batch queries\n",
    "batch_responses = rag_chain.batch_invoke(test_queries)\n",
    "\n",
    "# Display results\n",
    "for i, (query, response) in enumerate(zip(test_queries, batch_responses), 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Query {i}: {query}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\n{response.answer[:500]}...\" if len(response.answer) > 500 else f\"\\n{response.answer}\")\n",
    "    print(f\"\\n‚è±Ô∏è Time: {response.retrieval_time + response.generation_time:.2f}s | Sources: {response.num_sources}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3daf0ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Batch Query Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>retrieval_time</th>\n",
       "      <th>generation_time</th>\n",
       "      <th>total_time</th>\n",
       "      <th>num_sources</th>\n",
       "      <th>answer_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which candidates have experience with machine lear...</td>\n",
       "      <td>0.522698</td>\n",
       "      <td>3.878551</td>\n",
       "      <td>4.401249</td>\n",
       "      <td>6</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Find candidates with AWS certifications...</td>\n",
       "      <td>0.316054</td>\n",
       "      <td>4.058564</td>\n",
       "      <td>4.374619</td>\n",
       "      <td>6</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who has product management experience at enterpris...</td>\n",
       "      <td>0.369751</td>\n",
       "      <td>2.785642</td>\n",
       "      <td>3.155394</td>\n",
       "      <td>6</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which designers have won awards for their work?...</td>\n",
       "      <td>0.322448</td>\n",
       "      <td>2.738126</td>\n",
       "      <td>3.060575</td>\n",
       "      <td>6</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Compare the education backgrounds of all candidate...</td>\n",
       "      <td>0.720248</td>\n",
       "      <td>8.487695</td>\n",
       "      <td>9.207943</td>\n",
       "      <td>6</td>\n",
       "      <td>1549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   query  retrieval_time  \\\n",
       "0  Which candidates have experience with machine lear...        0.522698   \n",
       "1             Find candidates with AWS certifications...        0.316054   \n",
       "2  Who has product management experience at enterpris...        0.369751   \n",
       "3     Which designers have won awards for their work?...        0.322448   \n",
       "4  Compare the education backgrounds of all candidate...        0.720248   \n",
       "\n",
       "   generation_time  total_time  num_sources  answer_length  \n",
       "0         3.878551    4.401249            6            751  \n",
       "1         4.058564    4.374619            6            492  \n",
       "2         2.785642    3.155394            6            670  \n",
       "3         2.738126    3.060575            6            474  \n",
       "4         8.487695    9.207943            6           1549  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch timing summary\n",
    "batch_df = pd.DataFrame([\n",
    "    {\n",
    "        \"query\": q[:50] + \"...\",\n",
    "        \"retrieval_time\": r.retrieval_time,\n",
    "        \"generation_time\": r.generation_time,\n",
    "        \"total_time\": r.retrieval_time + r.generation_time,\n",
    "        \"num_sources\": r.num_sources,\n",
    "        \"answer_length\": len(r.answer),\n",
    "    }\n",
    "    for q, r in zip(test_queries, batch_responses)\n",
    "])\n",
    "\n",
    "print(\"üìä Batch Query Summary:\")\n",
    "batch_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffa04ac",
   "metadata": {},
   "source": [
    "## 7. Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "397972dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öñÔ∏è Evaluation Pipeline initialized\n",
      "   Judge Model: mistralai/mistral-7b-instruct:free\n"
     ]
    }
   ],
   "source": [
    "from src.eval.pipeline import EvaluationPipeline\n",
    "\n",
    "# Create evaluation pipeline\n",
    "eval_pipeline = EvaluationPipeline.from_config(config)\n",
    "print(f\"‚öñÔ∏è Evaluation Pipeline initialized\")\n",
    "print(f\"   Judge Model: {config.judge.model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38ead89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluating 5 responses...\n",
      "\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-min. ', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '16', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1768476300000'}, 'provider_name': None}}, 'user_id': 'user_38G32QtBpDVH8VepQay5IcVq2kr'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Evaluate batch responses\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müîç Evaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(batch_responses)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m responses...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m eval_results = \u001b[43meval_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_responses\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abrah\\RAG\\src\\eval\\pipeline.py:173\u001b[39m, in \u001b[36mEvaluationPipeline.evaluate_batch\u001b[39m\u001b[34m(self, rag_responses)\u001b[39m\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(rag_responses, \u001b[32m1\u001b[39m):\n\u001b[32m    172\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEvaluating response \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(rag_responses)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m     results.append(result)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abrah\\RAG\\src\\eval\\pipeline.py:115\u001b[39m, in \u001b[36mEvaluationPipeline.evaluate_response\u001b[39m\u001b[34m(self, rag_response)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# Run all evaluations\u001b[39;00m\n\u001b[32m    113\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEvaluating response for query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrag_response.query[:\u001b[32m50\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m judge_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjudge\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate_all\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrag_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrag_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Calculate average score\u001b[39;00m\n\u001b[32m    122\u001b[39m scores = [\n\u001b[32m    123\u001b[39m     judge_results[\u001b[33m\"\u001b[39m\u001b[33mrelevance\u001b[39m\u001b[33m\"\u001b[39m].score,\n\u001b[32m    124\u001b[39m     judge_results[\u001b[33m\"\u001b[39m\u001b[33mfaithfulness\u001b[39m\u001b[33m\"\u001b[39m].score,\n\u001b[32m    125\u001b[39m     judge_results[\u001b[33m\"\u001b[39m\u001b[33mcorrectness\u001b[39m\u001b[33m\"\u001b[39m].score,\n\u001b[32m    126\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abrah\\RAG\\src\\eval\\judge.py:253\u001b[39m, in \u001b[36mLLMJudge.evaluate_all\u001b[39m\u001b[34m(self, question, answer, context)\u001b[39m\n\u001b[32m    251\u001b[39m results[\u001b[33m\"\u001b[39m\u001b[33mrelevance\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.evaluate_relevance(question, answer, context)\n\u001b[32m    252\u001b[39m results[\u001b[33m\"\u001b[39m\u001b[33mfaithfulness\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.evaluate_faithfulness(question, answer, context)\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m results[\u001b[33m\"\u001b[39m\u001b[33mcorrectness\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate_correctness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abrah\\RAG\\src\\eval\\judge.py:222\u001b[39m, in \u001b[36mLLMJudge.evaluate_correctness\u001b[39m\u001b[34m(self, question, answer, context)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[33;03mEvaluate answer correctness and quality.\u001b[39;00m\n\u001b[32m    207\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    214\u001b[39m \u001b[33;03m    JudgeResult with score and explanation.\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    216\u001b[39m prompt = \u001b[38;5;28mself\u001b[39m.prompts[\u001b[33m\"\u001b[39m\u001b[33mcorrectness\u001b[39m\u001b[33m\"\u001b[39m].format(\n\u001b[32m    217\u001b[39m     question=question,\n\u001b[32m    218\u001b[39m     answer=answer,\n\u001b[32m    219\u001b[39m     context=context,\n\u001b[32m    220\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m raw_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_judge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    223\u001b[39m score, explanation = parse_judge_response(raw_response)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m JudgeResult(\n\u001b[32m    226\u001b[39m     metric=\u001b[33m\"\u001b[39m\u001b[33mcorrectness\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m     score=score,\n\u001b[32m    228\u001b[39m     explanation=explanation,\n\u001b[32m    229\u001b[39m     raw_response=raw_response,\n\u001b[32m    230\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abrah\\RAG\\src\\eval\\judge.py:122\u001b[39m, in \u001b[36mLLMJudge._call_judge\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call_judge\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    113\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    114\u001b[39m \u001b[33;03m    Call the judge model.\u001b[39;00m\n\u001b[32m    115\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    120\u001b[39m \u001b[33;03m        Judge response.\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.choices[\u001b[32m0\u001b[39m].message.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abrah\\RAG\\.conda\\Lib\\site-packages\\openai\\_utils\\_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abrah\\RAG\\.conda\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1192\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1145\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1147\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1189\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1190\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1191\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1215\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1229\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1230\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1232\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abrah\\RAG\\.conda\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abrah\\RAG\\.conda\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-min. ', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '16', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1768476300000'}, 'provider_name': None}}, 'user_id': 'user_38G32QtBpDVH8VepQay5IcVq2kr'}"
     ]
    }
   ],
   "source": [
    "# Evaluate batch responses\n",
    "print(f\"üîç Evaluating {len(batch_responses)} responses...\\n\")\n",
    "\n",
    "eval_results = eval_pipeline.evaluate_batch(batch_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5c266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display evaluation results as DataFrame\n",
    "eval_df = eval_pipeline.to_dataframe()\n",
    "\n",
    "# Select key columns for display\n",
    "display_columns = [\n",
    "    'query', 'relevance_score', 'faithfulness_score', \n",
    "    'correctness_score', 'average_score'\n",
    "]\n",
    "\n",
    "print(\"üìä Evaluation Results:\")\n",
    "eval_df[display_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ca54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "summary = eval_pipeline.get_summary_stats()\n",
    "\n",
    "print(\"\\nüìà Evaluation Summary:\")\n",
    "print(f\"   Number of evaluations: {summary['num_evaluations']}\")\n",
    "print(f\"   Avg Relevance Score: {summary['avg_relevance']}/5\")\n",
    "print(f\"   Avg Faithfulness Score: {summary['avg_faithfulness']}/5\")\n",
    "print(f\"   Avg Correctness Score: {summary['avg_correctness']}/5\")\n",
    "print(f\"   Overall Average Score: {summary['avg_overall']}/5\")\n",
    "print(f\"   Avg Retrieval Time: {summary['avg_retrieval_time']:.3f}s\")\n",
    "print(f\"   Avg Generation Time: {summary['avg_generation_time']:.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cca23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Evaluation Scores Bar Chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "metrics = ['relevance_score', 'faithfulness_score', 'correctness_score']\n",
    "metric_labels = ['Relevance', 'Faithfulness', 'Correctness']\n",
    "x = range(len(eval_df))\n",
    "width = 0.25\n",
    "\n",
    "for i, (metric, label) in enumerate(zip(metrics, metric_labels)):\n",
    "    offset = (i - 1) * width\n",
    "    ax.bar([xi + offset for xi in x], eval_df[metric], width, label=label)\n",
    "\n",
    "ax.set_xlabel('Query Index')\n",
    "ax.set_ylabel('Score (1-5)')\n",
    "ax.set_title('Evaluation Scores by Query')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'Q{i+1}' for i in x])\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 5.5)\n",
    "ax.axhline(y=4, color='green', linestyle='--', alpha=0.5, label='Good threshold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./outputs/eval_scores_chart.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Chart saved to ./outputs/eval_scores_chart.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Average Scores Pie Chart\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "avg_scores = [\n",
    "    summary['avg_relevance'],\n",
    "    summary['avg_faithfulness'],\n",
    "    summary['avg_correctness'],\n",
    "]\n",
    "\n",
    "colors = ['#3498db', '#2ecc71', '#9b59b6']\n",
    "explode = (0.05, 0.05, 0.05)\n",
    "\n",
    "ax.pie(\n",
    "    avg_scores, \n",
    "    labels=metric_labels, \n",
    "    autopct='%1.1f',\n",
    "    colors=colors,\n",
    "    explode=explode,\n",
    "    startangle=90,\n",
    ")\n",
    "ax.set_title(f'Average Scores Distribution\\n(Overall: {summary[\"avg_overall\"]}/5)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./outputs/avg_scores_pie.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514f9571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evaluation results\n",
    "eval_pipeline.save_results(\n",
    "    csv_filename=config.outputs.eval_csv,\n",
    "    json_filename=config.outputs.eval_json,\n",
    ")\n",
    "\n",
    "print(f\"\\nüíæ Results saved to:\")\n",
    "print(f\"   - {config.outputs.dir}/{config.outputs.eval_csv}\")\n",
    "print(f\"   - {config.outputs.dir}/{config.outputs.eval_json}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1002346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detailed explanations\n",
    "print(\"\\nüìã Detailed Evaluation Explanations:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, result in enumerate(eval_results, 1):\n",
    "    print(f\"\\nQuery {i}: {result.query[:60]}...\")\n",
    "    print(f\"  Relevance ({result.relevance_score}/5): {result.relevance_explanation[:100]}...\")\n",
    "    print(f\"  Faithfulness ({result.faithfulness_score}/5): {result.faithfulness_explanation[:100]}...\")\n",
    "    print(f\"  Correctness ({result.correctness_score}/5): {result.correctness_explanation[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c65d42d",
   "metadata": {},
   "source": [
    "## 8. Retrieval Evaluation (No LLM Required)\n",
    "\n",
    "This section evaluates **retrieval quality only** ‚Äî no LLM generation needed.\n",
    "We measure how well the retriever finds relevant CV chunks given ground-truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea15c146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.eval.retrieval_eval import (\n",
    "    RetrievalEvaluator,\n",
    "    load_retrieval_eval_data,\n",
    "    get_aggregate_metrics,\n",
    ")\n",
    "\n",
    "# Load retrieval evaluation dataset\n",
    "eval_data_path = \"./data/eval/retrieval_eval.jsonl\"\n",
    "retrieval_dataset = load_retrieval_eval_data(eval_data_path)\n",
    "\n",
    "print(f\"üìÇ Loaded {len(retrieval_dataset)} retrieval evaluation queries\")\n",
    "print(\"\\nSample queries:\")\n",
    "for i, q in enumerate(retrieval_dataset[:3], 1):\n",
    "    print(f\"  {i}. {q.query[:60]}...\")\n",
    "    print(f\"     Expected candidates: {q.expected_candidate_ids}\")\n",
    "    print(f\"     Expected sections: {q.expected_section_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c60cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retrieval evaluator and run evaluation\n",
    "retrieval_evaluator = RetrievalEvaluator(\n",
    "    chroma_store=chroma_store,\n",
    "    top_k=config.retrieval.top_k,\n",
    ")\n",
    "\n",
    "print(f\"üîç Running retrieval evaluation with top_k={config.retrieval.top_k}...\\n\")\n",
    "\n",
    "retrieval_results_df = retrieval_evaluator.evaluate(retrieval_dataset)\n",
    "\n",
    "print(f\"‚úÖ Evaluated {len(retrieval_results_df)} queries\")\n",
    "retrieval_results_df[[\"query\", \"hit_at_k\", \"precision_at_k\", \"recall_at_k\", \"mrr_at_k\", \"ndcg_at_k\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241ab5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate metrics summary\n",
    "summary = retrieval_evaluator.get_summary()\n",
    "\n",
    "print(\"üìä Retrieval Evaluation Summary:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Number of queries:     {summary['num_queries']}\")\n",
    "print(f\"  Avg Hit@k:             {summary['avg_hit_at_k']:.3f}\")\n",
    "print(f\"  Avg Precision@k:       {summary['avg_precision_at_k']:.3f}\")\n",
    "print(f\"  Avg Recall@k:          {summary['avg_recall_at_k']:.3f}\")\n",
    "print(f\"  Avg MRR@k:             {summary['avg_mrr_at_k']:.3f}\")\n",
    "print(f\"  Avg nDCG@k:            {summary['avg_ndcg_at_k']:.3f}\")\n",
    "print(f\"  Total relevant found:  {summary['total_relevant_retrieved']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad89e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Retrieval Metrics Bar Chart\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Per-query metrics\n",
    "ax1 = axes[0]\n",
    "metrics_to_plot = [\"hit_at_k\", \"precision_at_k\", \"recall_at_k\", \"mrr_at_k\"]\n",
    "x = range(len(retrieval_results_df))\n",
    "width = 0.2\n",
    "\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    offset = (i - 1.5) * width\n",
    "    ax1.bar([xi + offset for xi in x], retrieval_results_df[metric], width, label=metric.replace(\"_at_k\", \"\").title())\n",
    "\n",
    "ax1.set_xlabel(\"Query Index\")\n",
    "ax1.set_ylabel(\"Score (0-1)\")\n",
    "ax1.set_title(\"Retrieval Metrics by Query\")\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels([f\"Q{i+1}\" for i in x], rotation=45)\n",
    "ax1.legend(loc=\"upper right\")\n",
    "ax1.set_ylim(0, 1.1)\n",
    "ax1.axhline(y=0.5, color=\"orange\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# Aggregate metrics\n",
    "ax2 = axes[1]\n",
    "agg_metrics = [\"avg_hit_at_k\", \"avg_precision_at_k\", \"avg_recall_at_k\", \"avg_mrr_at_k\", \"avg_ndcg_at_k\"]\n",
    "agg_labels = [\"Hit@k\", \"Precision@k\", \"Recall@k\", \"MRR@k\", \"nDCG@k\"]\n",
    "agg_values = [summary[m] for m in agg_metrics]\n",
    "colors = [\"#3498db\", \"#2ecc71\", \"#e74c3c\", \"#9b59b6\", \"#f39c12\"]\n",
    "\n",
    "bars = ax2.bar(agg_labels, agg_values, color=colors)\n",
    "ax2.set_ylabel(\"Average Score (0-1)\")\n",
    "ax2.set_title(\"Aggregate Retrieval Metrics\")\n",
    "ax2.set_ylim(0, 1.1)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, val in zip(bars, agg_values):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, f\"{val:.2f}\", \n",
    "             ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./outputs/retrieval_eval_chart.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Chart saved to ./outputs/retrieval_eval_chart.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132d834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save retrieval evaluation results\n",
    "retrieval_evaluator.save_results(\n",
    "    output_dir=\"./outputs\",\n",
    "    csv_filename=\"retrieval_eval_results.csv\",\n",
    "    json_filename=\"retrieval_eval_results.json\",\n",
    ")\n",
    "\n",
    "print(\"üíæ Results saved to:\")\n",
    "print(\"   - ./outputs/retrieval_eval_results.csv\")\n",
    "print(\"   - ./outputs/retrieval_eval_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c5e12b",
   "metadata": {},
   "source": [
    "## üéâ Complete!\n",
    "\n",
    "This notebook demonstrated the full CV RAG pipeline:\n",
    "\n",
    "1. ‚úÖ Configuration loading\n",
    "2. ‚úÖ CV data loading\n",
    "3. ‚úÖ Semantic chunking by CV sections\n",
    "4. ‚úÖ Embedding generation and Chroma indexing\n",
    "5. ‚úÖ Single query RAG\n",
    "6. ‚úÖ Batch query processing\n",
    "7. ‚úÖ LLM-as-judge evaluation\n",
    "8. ‚úÖ **Retrieval evaluation** (Hit@k, Precision@k, Recall@k, MRR@k, nDCG@k)\n",
    "\n",
    "### Next Steps:\n",
    "- Run the Streamlit app: `streamlit run app.py`\n",
    "- Customize prompts in `src/prompts/templates.py`\n",
    "- Add more CVs to `data/cvs.csv`\n",
    "- Add more retrieval eval queries to `data/eval/retrieval_eval.jsonl`\n",
    "- Experiment with different models in `config.yaml`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

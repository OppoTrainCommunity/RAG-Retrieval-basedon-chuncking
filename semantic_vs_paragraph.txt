Comparison of Semantic vs Paragraph Chunking

Both chunking strategies achieved strong retrieval performance, but semantic chunking consistently outperformed paragraph-based chunking across all evaluation metrics. Semantic chunks align with the natural structure of resumes (skills, experience, projects, education), which creates cleaner and more meaningful embedding representations.

Paragraph-based chunking produced a larger number of smaller, less coherent chunks, slightly increasing noise in the vector space. This resulted in small but measurable reductions in Precision@10, MAP, and nDCG.

Overall, semantic chunking is the superior strategy for resume indexing within a RAG system, offering better ranking quality and higher relevance in top-k retrieval.

| Metric       | Semantic   | Paragraph | Winner                         |
| ------------ | ---------- | --------- | ------------------------------ |
| Precision@10 | 0.8550 | 0.8540    | Semantic                       |
| Recall@10    | 0.2246 | 0.2236    | Semantic                       |
| MAP          | 0.8535 | 0.8502    | Semantic                       |
| nDCG@10      | 0.8941 | 0.8938    | Semantic                       |
| Total Chunks | 4495   | 5183      | Semantic (fewer, more focused) |


Why Semantic Chunking Performs Better

Even though the difference seems small, it makes sense:

ðŸ§  1. Semantic chunks = more meaningful units

the semantic chunker uses headings like:

SKILLS

EXPERIENCE

EDUCATION

PROJECTS

Meaning each chunk is self-contained and focused. Embeddings love that.

ðŸ“„ 2. Paragraph chunking = arbitrary splits

Paragraphs arenâ€™t guaranteed to represent meaningful semantic units.
A paragraph might contain:

- half of a skill list

- mixed topics

- incomplete sentences

Vector similarity suffers slightly.

ðŸ’¡ 3. Larger chunks in paragraph method dilute meaning

the paragraph chunking produced more chunks (5183) vs 4495 for semantic.
More chunks â†’ more noise â†’ slight drop in MAP and nDCG.
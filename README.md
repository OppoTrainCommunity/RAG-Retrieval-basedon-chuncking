# CV-Based Career Path Recommendation System â€“ Retrieval Component

## ğŸ“‹ Overview

This project implements the **retrieval component** of a Retrieval-Augmented Generation (RAG) system designed to analyze resumes/CVs and extract relevant information for career path recommendations. The system reads PDF CVs, chunks them using multiple strategies, embeds them with sentence transformers, stores them in ChromaDB, and retrieves relevant sections based on semantic similarity.

**Scope:** This repository contains **retrieval and indexing only** â€” no LLM generation or UI (Streamlit/Gradio) code is included.

---

## ğŸ¯ Main Idea

Traditional keyword-based resume search is limited. This system uses **semantic search** to understand the meaning of queries and match them to relevant CV sections, even if the exact keywords don't appear. The workflow:

1. **Read** â†’ Extract text from PDF files
2. **Chunk** â†’ Split text into meaningful segments (4 strategies available)
3. **Embed** â†’ Convert chunks to high-dimensional vectors using pre-trained models
4. **Store** â†’ Index embeddings in ChromaDB for fast retrieval
5. **Query** â†’ Use semantic similarity to find relevant resume sections
6. **Display** â†’ Show top-k results with similarity scores

This enables intelligent extraction of:
- Technical skills and competencies
- Project experience and achievements
- Education and certifications
- Internship details and job history
- Contact information

---

## ğŸ”§ Installation

### Prerequisites

- **Python** 3.8 or higher
- **pip** package manager

### Step 1: Clone or Download the Repository

```bash
cd c:\Users\Lenovo\Desktop\train.2\RAG\Retrieval_Task
```

### Step 2: Install Dependencies

```bash
pip install chromadb sentence-transformers pymupdf nltk
```

**Package Details:**

| Package | Version | Purpose |
|---------|---------|---------|
| `chromadb` | Latest | Vector database for storing and retrieving embeddings |
| `sentence-transformers` | Latest | Pre-trained models for converting text to embeddings |
| `pymupdf` (fitz) | Latest | PDF reading and text extraction |
| `nltk` | Latest | Natural Language Toolkit for sentence tokenization |

### Step 3: Download NLTK Data

The notebook automatically downloads the `punkt` tokenizer on first run, but you can pre-download it:

```bash
python -c "import nltk; nltk.download('punkt')"
```

### Step 4: Prepare Your Data

Create the following folder structure in your project directory:

```
Retrieval_Task/
â”œâ”€â”€ retrieval.ipynb
â”œâ”€â”€ questions.txt
â”œâ”€â”€ cvs/
â”‚   â”œâ”€â”€ resume1.pdf
â”‚   â”œâ”€â”€ resume2.pdf
â”‚   â””â”€â”€ ...
â””â”€â”€ README.md
```

**CVs Folder:** Place your resume PDF files in the `cvs/` folder.

**questions.txt:** Create a text file with one question per line. Example:

```
What are my technical skills?
What projects have I worked on?
Do I have internship experience?
What is my email?
What is my GPA?
```

---

## ğŸ“Š Chunking Methods Comparison

The system supports four text chunking strategies. Each has trade-offs:

### 1. **Sentence-Based Chunking**

```python
def sentence_chunking(text, max_sentences=5):
    sentences = sent_tokenize(text)
    return [" ".join(sentences[i:i+max_sentences]) for i in range(0, len(sentences), max_sentences)]
```

| Aspect | Rating | Notes |
|--------|--------|-------|
| **Granularity** | Medium | Groups 5 sentences together |
| **Context Preservation** | High | Natural sentence boundaries |
| **Query Matching** | Good | Works well for question-based queries |
| **Speed** | Fast | Minimal preprocessing |
| **Use Case** | â­ Recommended for QA systems | Best for "What" and "How" questions |

**Pros:**
- Natural language boundaries
- Good context preservation
- Fast processing
- Ideal for FAQ-style retrieval

**Cons:**
- Variable chunk sizes (some sentences are longer)
- May split related information

---

### 2. **Paragraph-Based Chunking**

```python
def paragraph_chunking(text):
    paragraphs = [p for p in text.split("\n") if len(p.strip()) > 0]
    return paragraphs
```

| Aspect | Rating | Notes |
|--------|--------|-------|
| **Granularity** | Coarse | Full paragraphs as chunks |
| **Context Preservation** | Very High | Maintains paragraph structure |
| **Query Matching** | Excellent | Large context windows |
| **Speed** | Very Fast | No NLP processing |
| **Use Case** | Best for coherent sections | Works for CV structure |

**Pros:**
- Preserves document structure
- Fastest method
- Maximum context per chunk
- Great for structured documents

**Cons:**
- Highly variable chunk sizes
- May create very large embeddings
- Less suitable for dense information

---

### 3. **Semantic-Based Chunking (Fixed Window)**

```python
def semantic_chunking(text, size=120, overlap=40):
    words = text.split()
    chunks = []
    step = size - overlap
    for i in range(0, len(words), step):
        chunks.append(" ".join(words[i:i+size]))
    return chunks
```

| Aspect | Rating | Notes |
|--------|--------|-------|
| **Granularity** | Fine | 120 words per chunk |
| **Context Preservation** | Good | 40-word overlap |
| **Query Matching** | Very Good | Balanced chunk size |
| **Speed** | Fast | Simple word splitting |
| **Use Case** | â­â­ General purpose | Best all-around choice |

**Pros:**
- Uniform chunk size (easier for embeddings)
- Overlap prevents boundary artifacts
- Good balance of detail vs. context
- Industry standard approach

**Cons:**
- May split sentences awkwardly at boundaries
- Overlap increases storage overhead
- Less aware of semantic boundaries

---

### 4. **Sliding Window Chunking (Optimized)**

```python
def sliding_window_chunking(text, chunk_size=120, overlap=40):
    words = text.split()
    chunks = []
    step = chunk_size - overlap
    for i in range(0, len(words), step):
        chunk_words = words[i:i + chunk_size]
        if not chunk_words:
            break
        chunk = " ".join(chunk_words)
        chunks.append(chunk)
    return chunks
```

| Aspect | Rating | Notes |
|--------|--------|-------|
| **Granularity** | Fine | 120 words, checked boundaries |
| **Context Preservation** | Good | 40-word overlap with validation |
| **Query Matching** | Excellent | Consistent, clean chunks |
| **Speed** | Fast | Minimal validation overhead |
| **Use Case** | â­â­â­ Production recommended | Most robust approach |

**Pros:**
- Prevents empty chunks
- Consistent quality
- Sliding window ensures smooth transitions
- Best for production systems

**Cons:**
- Slightly slower than semantic chunking
- Minimal performance difference

---

## ğŸ§  Embedding Models Comparison

The system supports three sentence-transformer models:

### 1. **all-MiniLM-L6-v2** (Default)

| Metric | Value |
|--------|-------|
| **Dimensions** | 384 |
| **Parameters** | 22M |
| **Speed** | â­â­â­â­â­ Fastest |
| **Accuracy** | â­â­â­ Good |
| **Memory** | â­â­â­â­â­ Minimal (~50 MB) |
| **Training Data** | 215M sentence pairs |
| **Use Case** | Fast retrieval, real-time applications |

**Best For:** Production systems needing speed and low memory.

---

### 2. **all-mpnet-base-v2**

| Metric | Value |
|--------|-------|
| **Dimensions** | 768 |
| **Parameters** | 110M |
| **Speed** | â­â­â­ Moderate |
| **Accuracy** | â­â­â­â­ Very Good |
| **Memory** | â­â­â­ ~220 MB |
| **Training Data** | 260M sentence pairs |
| **Use Case** | Balance of accuracy and performance |

**Best For:** Production systems prioritizing accuracy with reasonable performance.

---

### 3. **paraphrase-mpnet-base-v2** (Recommended for Quality)

| Metric | Value |
|--------|-------|
| **Dimensions** | 768 |
| **Parameters** | 110M |
| **Speed** | â­â­â­ Moderate |
| **Accuracy** | â­â­â­â­â­ Excellent |
| **Memory** | â­â­â­ ~220 MB |
| **Training Data** | Paraphrase-focused corpus |
| **Use Case** | Semantic understanding of variations |

**Best For:** High-accuracy retrieval, handling paraphrases and synonyms.

---

### Model Comparison Table

| Model | Speed | Accuracy | Memory | Cost | Best For |
|-------|-------|----------|--------|------|----------|
| all-MiniLM-L6-v2 | â­â­â­â­â­ | â­â­â­ | â­â­â­â­â­ | Lowest | Real-time, mobile |
| all-mpnet-base-v2 | â­â­â­ | â­â­â­â­ | â­â­â­ | Medium | Production balance |
| paraphrase-mpnet-base-v2 | â­â­â­ | â­â­â­â­â­ | â­â­â­ | Medium | High accuracy needed |

---

## ğŸš€ Quick Start

### 1. Run the Notebook

```bash
jupyter notebook retrieval.ipynb
```

### 2. Execute Cells Sequentially

- **Cell 1:** Install packages (uncomment if needed)
- **Cell 2:** Import libraries and environment setup
- **Cells 3-8:** Define chunking and embedding functions
- **Cell 9:** Main pipeline execution

### 3. Follow Interactive Prompts

The notebook will ask you to choose:

```
ğŸ”¹ Select Chunking Method:
1ï¸âƒ£ Sentence-based
2ï¸âƒ£ Paragraph-based
3ï¸âƒ£ Semantic-based
4ï¸âƒ£ Sliding Window-based

âœ¨ Choose Embedding Model:
1ï¸âƒ£ all-MiniLM-L6-v2  (Fast - Good)
2ï¸âƒ£ all-mpnet-base-v2  (Higher Accuracy)
3ï¸âƒ£ paraphrase-mpnet-base-v2 (Excellent)
```

### 4. View Results

The system will output:

```
ğŸ“Œ RESULTS FOR CV: resume1.pdf
==============================================================================
ğŸ” Query: What are my technical skills?
--------------------------------------------------

â­ Result #1
ID: resume1_chunk_5
Similarity: 0.8234
Text:
[Relevant excerpt from CV...]

â­ Result #2
ID: resume1_chunk_12
Similarity: 0.7891
Text:
[Related content...]
```

---

## ğŸ“ Project Structure

```
Retrieval_Task/
â”‚
â”œâ”€â”€ retrieval.ipynb           # Main notebook with complete pipeline
â”œâ”€â”€ questions.txt             # Query file (one per line)
â”œâ”€â”€ README.md                 # This file
â”‚
â””â”€â”€ cvs/                      # CV storage folder
    â”œâ”€â”€ resume1.pdf
    â”œâ”€â”€ resume2.pdf
    â””â”€â”€ ...
```

---

## ğŸ” How It Works

### Step-by-Step Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Read PDF CVs   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Choose Chunking Method â”‚
â”‚  (4 strategies)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Split Text into Chunks  â”‚
â”‚  (120 words, 40 overlap) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Choose Embedding Model      â”‚
â”‚  (3 options available)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Generate Embeddings     â”‚
â”‚  (384-768 dimensions)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Store in ChromaDB       â”‚
â”‚  (Vector database)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Load Questions File     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  For Each Question:            â”‚
â”‚  1. Embed question             â”‚
â”‚  2. Find top-3 similar chunks  â”‚
â”‚  3. Display results            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Output Results          â”‚
â”‚  (With similarity score) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Key Concepts

### Vector Embeddings

Embeddings convert text into numerical vectors that capture semantic meaning. Similar texts have similar embeddings, allowing us to find relevant content using vector similarity.

```python
"What are your skills?" â†’ [0.12, -0.45, 0.89, ..., 0.34]  # 384-dimensional vector
```

### ChromaDB

A lightweight vector database that stores embeddings and allows fast similarity search. It's optimized for RAG applications.

### Cosine Similarity

The system uses cosine distance to measure similarity between query and chunk embeddings. Lower distance = higher similarity.

```
Similarity Score = 1 - Distance
Range: 0 (different) to 1 (identical)
```

---

## ğŸ“ˆ Performance Metrics

### Retrieval Speed

- **Query Time:** ~100-500ms (single query)
- **Indexing Time:** ~5-15s (100 chunks)
- **Storage:** ~100 KB per CV (depends on length)

### Accuracy Comparison

| Model | MRR@10 | NDCG@10 | Suitable For |
|-------|--------|---------|---|
| MiniLM | 0.72 | 0.68 | Fast retrieval |
| MPNet | 0.78 | 0.74 | Balanced |
| Paraphrase-MPNet | 0.82 | 0.79 | High accuracy |

---

## ğŸ› Troubleshooting

### Issue: `ModuleNotFoundError: No module named 'sentence_transformers'`

**Solution:**
```bash
pip install sentence-transformers
```

### Issue: `FileNotFoundError: [Errno 2] No such file or directory: 'cvs'`

**Solution:** Create a `cvs/` folder in the same directory as the notebook and add your PDF files.

### Issue: `FileNotFoundError: [Errno 2] No such file or directory: 'questions.txt'`

**Solution:** Create a `questions.txt` file with your queries (one per line).

### Issue: `ValueError: Your currently installed version of Keras is Keras 3`

**Solution:**
```bash
pip install tf-keras
```

or use the environment variable in the notebook:
```python
os.environ["TRANSFORMERS_NO_TF"] = "1"
```

---

## ğŸ’¡ Recommendations

### For Production Use:

1. **Chunking:** Use **Sliding Window (Method 4)** for consistency
2. **Embedding:** Use **paraphrase-mpnet-base-v2** for quality
3. **Top-K:** Retrieve top 3-5 results for balance
4. **Database:** Consider persistent ChromaDB or Pinecone for scaling

### For Development/Testing:

1. **Chunking:** Use **Semantic (Method 3)** for quick iteration
2. **Embedding:** Use **all-MiniLM-L6-v2** for speed
3. **Top-K:** Retrieve top 3 results
4. **Database:** In-memory ChromaDB is fine

### For High-Accuracy Retrieval:

1. **Chunking:** Sentence-based (Method 1) preserves context
2. **Embedding:** paraphrase-mpnet-base-v2 (Method 3)
3. **Preprocessing:** Add domain-specific synonyms
4. **Query Expansion:** Use multiple similar query phrasings

---

## ğŸ“š Next Steps

After retrieval, integrate with:

1. **LLM Integration** (Together AI / OpenRouter)
   - Use retrieved chunks as context
   - Generate career path recommendations
   
2. **UI Development** (Streamlit / Gradio)
   - Upload CV interface
   - Query input and results display
   - Career path visualization

3. **Production Deployment**
   - Docker containerization
   - API endpoint creation
   - Database persistence

---

## ğŸ“„ License

This project is open source and available under the MIT License.

---

## ğŸ‘¨â€ğŸ’» Author Notes

**This is the retrieval component only.** It demonstrates how to:
- Read and preprocess PDFs
- Implement multiple chunking strategies
- Work with embeddings and vector databases
- Perform semantic search

For a complete career recommendation system, extend this with an LLM backend and web interface.

---

## ğŸ“ Support

For issues or questions:
1. Check the Troubleshooting section
2. Review the chunking/embedding comparisons
3. Ensure all files (`cvs/`, `questions.txt`) are properly set up
4. Verify all dependencies are installed

---

**Happy Retrieving! ğŸš€**


# ğŸ“„ RAG Retrieval Evaluation â€” Chunking Strategies  
This repository contains an end-to-end evaluation framework for **Resume-Based RAG (Retrieval-Augmented Generation)** using **two different chunking strategies**.  
The goal of this work is to measure the effect of chunking on retrieval accuracy, latency, and ranking quality.

---

# ğŸš€ Project Overview
This project implements:

1. **PDF Parsing**  
   - Extract text content from raw resume PDFs.

2. **Chunking Strategies**  
   - **Semantic Chunking** â†’ Based on CV section headers (Education, Experience, Projectsâ€¦ etc.)  
   - **Sliding Window Chunking** â†’ Fixed-size word windows with overlap.

3. **Vector Database (ChromaDB)**  
   - Each chunk is embedded using `all-MiniLM-L6-v2`.  
   - Stored in separate collections for each strategy.

4. **Retrieval Evaluation**  
   - Compare retrieval results against ground-truth for 15 well-defined queries.  
   - Metrics calculated for each strategy:
     - Precision@k  
     - Recall@k  
     - Hit Rate  
     - MRR (Mean Reciprocal Rank)  
     - Latency  

5. **Evaluation Report**  
   - Full results saved automatically into `evaluation_results.csv`

---

# ğŸ“¦ Directory Structure
```
RAG-Retrieval-basedon-chuncking/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ evaluation_results.csv
â”‚
â”œâ”€â”€ resume_rag/
â”‚   â”œâ”€â”€ chunker.py
â”‚   â”œâ”€â”€ llm_chain.py
â”‚   â”œâ”€â”€ parse_pdf.py
â”‚   â”œâ”€â”€ pipeline.py
â”‚   â”œâ”€â”€ evaluate_chunking.py
â”‚   â”œâ”€â”€vector_store_chain.py
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ assets/
â”‚   â”‚   â”œâ”€â”€ ibrahim_cv.pdf
â”‚   â”‚   â”œâ”€â”€ rama_cv.pdf
â”‚   â”‚   â”œâ”€â”€ toqa_cv.pdf
â”‚   â”‚   â”œâ”€â”€ tala_cv.pdf
â”‚   â”‚
â”‚   â””â”€â”€ resume_db/
â”‚
â””â”€â”€ .gitignore
```

---

# ğŸ§© Chunking Strategies

## **1. Semantic Chunking**
Divides the resume based on standard CV section headers:
- EDUCATION  
- EXPERIENCE  
- PROJECTS  
- SKILLS  
- CERTIFICATIONS  
- SUMMARY  

Suitable for structured questions such as:
- â€œWhat is the candidateâ€™s GPA?â€  
- â€œWhat university did the candidate attend?â€

## **2. Sliding Window Chunking**
A flexible chunking method using:
- **Window = 180 tokens**  
- **Overlap = 40 tokens**

This method increases contextual recall and works better for:
- Complex project descriptions  
- Skills queries  
- Multi-hop inference

---

# ğŸ“Š Evaluation Metrics

Each query is executed against both chunking strategies.  
We compute:

| Metric | Meaning |
|--------|---------|
| **Precision@k** | % of retrieved chunks that are correct |
| **Recall@k** | % of all correct chunks retrieved |
| **Hit Rate** | Whether any chunk contained the answer |
| **MRR** | Rank quality of first correct result |
| **Latency** | Retrieval time |

---

# ğŸ” Queries Used for Evaluation  
A set of 15 queries were selected to cover:

### âœ” Direct Information Retrieval  
- Email  
- Phone number  
- University  
- GPA  

### âœ” Experience  
- Internships  
- Trainings  
- Certifications  

### âœ” Projects  
- ML classification  
- MERN stack project details  
- ML models used in stock prediction system  

### âœ” Skills  
- Spark  
- React  
- YOLO  

Ground truth for each query is matched using substring comparison.

---

# ğŸ§ª Running the Evaluation

Run the evaluation script:

```bash
python -m resume_rag.evaluate_chunking
```

Or:

```bash
python resume_rag/evaluate_chunking.py
```

Results will appear in:

```
evaluation_results.csv
```

And a printed statistical summary shows which strategy performed better.

---

# ğŸ† Final Results Summary

| Strategy | Precision | Recall | Hit Rate | MRR | Latency |
|----------|-----------|--------|----------|-----|---------|
| **Semantic Chunking** | 0.25 | 0.62 | 0.64 | 0.50 | 0.0147s |
| **Sliding Window Chunking** | **0.35** | **0.86** | **1.00** | **0.73** | 0.0143s |

### âœ… **Winner: Sliding Window Chunking**  
Provides:
- Higher recall  
- More accurate retrieval  
- Better ranking quality  
- Stable low latency  

### Hybrid Recommendation  
Use:
- **Semantic** for structured Q&A  
- **Sliding Window** for long-context queries  

---

# ğŸ§· Usage in RAG Pipeline  
Chunk collections can be plugged directly into any RAG system using the functions in:
- `vector_store.py`
- `pipeline.py`
- `llm_chain.py`

---

# ğŸ‘©â€ğŸ’» Author  
Developed by **Tala Dweikat** as part of **OppoTrain RAG Task**.

---

# ğŸ“¬ Contact  
ğŸ“§ tala.nazeeh.dowiekat@gmail.com  
ğŸ”— GitHub: https://github.com/taladowiekat

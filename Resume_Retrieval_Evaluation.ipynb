{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ“Š Resume Retrieval System - RAG Evaluation\n",
                "\n",
                "## Ù†Ø¸Ø§Ù… Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… RAG\n",
                "\n",
                "### ðŸŽ¯ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:\n",
                "1. **PDF Upload & Parsing**: Ø±ÙØ¹ ÙˆØªØ­Ù„ÙŠÙ„ Ù…Ù„ÙØ§Øª PDF Ù„Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ©\n",
                "2. **3 Embedding Models**: Ø§Ø®ØªÙŠØ§Ø± Ù…Ù† 3 Ù†Ù…Ø§Ø°Ø¬ Ù…Ø®ØªÙ„ÙØ©\n",
                "3. **3 Chunking Strategies**: Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª ØªÙ‚Ø³ÙŠÙ… Ù…ØªØ¹Ø¯Ø¯Ø© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©\n",
                "4. **Top-K Retrieval**: Ø§Ù„ØªØ­ÙƒÙ… Ø¨Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (1-10)\n",
                "5. **Evaluation Metrics**: Ù…Ù‚Ø§ÙŠÙŠØ³ ØªÙ‚ÙŠÙŠÙ… Ø´Ø§Ù…Ù„Ø©\n",
                "6. **Interactive UI**: ÙˆØ§Ø¬Ù‡Ø© ØªÙØ§Ø¹Ù„ÙŠØ© Ù…ØªÙƒØ§Ù…Ù„Ø©\n",
                "\n",
                "### ðŸ“¦ Environment:\n",
                "- Python 3.11 (Conda)\n",
                "- VS Code Local Development\n",
                "- SentenceTransformer (Free, Offline)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“¦ Section 1: Install & Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "# Install required packages (run once)\n",
                "%pip install pandas chromadb sentence-transformers nltk pdfplumber gradio tabulate PyMuPDF --quiet"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… All libraries imported successfully!\n",
                        "ðŸ“‚ Working Directory: c:\\Users\\abrah\\RAG\n"
                    ]
                }
            ],
            "source": [
                "# Import libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import chromadb\n",
                "from chromadb.utils import embedding_functions\n",
                "from sentence_transformers import SentenceTransformer\n",
                "import nltk\n",
                "from nltk.tokenize import sent_tokenize, word_tokenize\n",
                "import pdfplumber\n",
                "import re\n",
                "import math\n",
                "import os\n",
                "from pathlib import Path\n",
                "from typing import List, Dict, Tuple, Any, Optional\n",
                "from collections import defaultdict\n",
                "from tabulate import tabulate\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Download NLTK data\n",
                "nltk.download('punkt', quiet=True)\n",
                "nltk.download('punkt_tab', quiet=True)\n",
                "\n",
                "print(\"âœ… All libraries imported successfully!\")\n",
                "print(f\"ðŸ“‚ Working Directory: {os.getcwd()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## âš™ï¸ Section 2: Configuration Settings\n",
                "\n",
                "### Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¹Ø¯ÙŠÙ„"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âš™ï¸ SYSTEM CONFIGURATION\n",
                        "==================================================\n",
                        "\n",
                        "ðŸ“¦ Embedding Models Available:\n",
                        "  â†’ MiniLM (Fast): all-MiniLM-L6-v2\n",
                        "    MPNet (High Quality): all-mpnet-base-v2\n",
                        "    BGE (Strong Retrieval): BAAI/bge-base-en-v1.5\n",
                        "\n",
                        "âœ‚ï¸ Chunking Settings:\n",
                        "   Chunk Size: 300-400 chars\n",
                        "   Overlap: 10%\n",
                        "\n",
                        "ðŸ” Top-K Range: 1-10 (Default: 3)\n",
                        "\n",
                        "ðŸ“ Directories:\n",
                        "   Upload: ./uploaded_resumes\n",
                        "   ChromaDB: ./chroma_db\n",
                        "\n",
                        "âœ… Configuration loaded!\n"
                    ]
                }
            ],
            "source": [
                "# ============================================\n",
                "# âš™ï¸ SYSTEM CONFIGURATION\n",
                "# ============================================\n",
                "\n",
                "class Config:\n",
                "    \"\"\"\n",
                "    Central configuration for the Resume RAG System.\n",
                "    All settings can be modified here or through the UI.\n",
                "    \"\"\"\n",
                "    \n",
                "    # -----------------------------------------\n",
                "    # ðŸ”¤ EMBEDDING MODELS (Free, Local)\n",
                "    # -----------------------------------------\n",
                "    EMBEDDING_MODELS = {\n",
                "        \"all-MiniLM-L6-v2\": {\n",
                "            \"name\": \"MiniLM (Fast)\",\n",
                "            \"description\": \"Lightweight, fast inference. Good for quick experiments.\",\n",
                "            \"dimension\": 384\n",
                "        },\n",
                "        \"all-mpnet-base-v2\": {\n",
                "            \"name\": \"MPNet (High Quality)\", \n",
                "            \"description\": \"Best quality for semantic similarity tasks.\",\n",
                "            \"dimension\": 768\n",
                "        },\n",
                "        \"BAAI/bge-base-en-v1.5\": {\n",
                "            \"name\": \"BGE (Strong Retrieval)\",\n",
                "            \"description\": \"Optimized for retrieval tasks. Strong semantic matching.\",\n",
                "            \"dimension\": 768\n",
                "        }\n",
                "    }\n",
                "    \n",
                "    DEFAULT_EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
                "    \n",
                "    # -----------------------------------------\n",
                "    # âœ‚ï¸ CHUNKING SETTINGS\n",
                "    # -----------------------------------------\n",
                "    CHUNKING_STRATEGIES = {\n",
                "        \"fixed\": \"Fixed-Length (300-400 chars)\",\n",
                "        \"sentence\": \"Sentence-Based\",\n",
                "        \"layout\": \"Layout-Aware (Sections/Headings)\"\n",
                "    }\n",
                "    \n",
                "    # Chunk parameters\n",
                "    CHUNK_SIZE = 350           # Target chunk size (chars)\n",
                "    CHUNK_SIZE_MIN = 300       # Minimum chunk size\n",
                "    CHUNK_SIZE_MAX = 400       # Maximum chunk size\n",
                "    CHUNK_OVERLAP_PERCENT = 10  # Overlap percentage (10%)\n",
                "    \n",
                "    @property\n",
                "    def chunk_overlap(self):\n",
                "        return int(self.CHUNK_SIZE * self.CHUNK_OVERLAP_PERCENT / 100)\n",
                "    \n",
                "    # Sentence-based settings\n",
                "    MAX_SENTENCES_PER_CHUNK = 5\n",
                "    \n",
                "    # -----------------------------------------\n",
                "    # ðŸ” RETRIEVAL SETTINGS\n",
                "    # -----------------------------------------\n",
                "    TOP_K_MIN = 1\n",
                "    TOP_K_MAX = 10\n",
                "    TOP_K_DEFAULT = 3  # Recommended for CV documents\n",
                "    \n",
                "    # -----------------------------------------\n",
                "    # ðŸ“ FILE SETTINGS\n",
                "    # -----------------------------------------\n",
                "    SUPPORTED_FORMATS = [\".pdf\", \".txt\"]\n",
                "    PDF_PARSER = \"pdfplumber\"  # Options: \"pdfplumber\", \"pymupdf\"\n",
                "    \n",
                "    # -----------------------------------------\n",
                "    # ðŸ“‚ STORAGE PATHS\n",
                "    # -----------------------------------------\n",
                "    UPLOAD_FOLDER = \"./uploaded_resumes\"\n",
                "    CHROMA_PERSIST_DIR = \"./chroma_db\"\n",
                "\n",
                "# Initialize config\n",
                "config = Config()\n",
                "\n",
                "# Create necessary directories\n",
                "os.makedirs(config.UPLOAD_FOLDER, exist_ok=True)\n",
                "os.makedirs(config.CHROMA_PERSIST_DIR, exist_ok=True)\n",
                "\n",
                "# Display configuration\n",
                "print(\"âš™ï¸ SYSTEM CONFIGURATION\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"\\nðŸ“¦ Embedding Models Available:\")\n",
                "for model_id, info in config.EMBEDDING_MODELS.items():\n",
                "    marker = \"â†’\" if model_id == config.DEFAULT_EMBEDDING_MODEL else \" \"\n",
                "    print(f\"  {marker} {info['name']}: {model_id}\")\n",
                "\n",
                "print(f\"\\nâœ‚ï¸ Chunking Settings:\")\n",
                "print(f\"   Chunk Size: {config.CHUNK_SIZE_MIN}-{config.CHUNK_SIZE_MAX} chars\")\n",
                "print(f\"   Overlap: {config.CHUNK_OVERLAP_PERCENT}%\")\n",
                "\n",
                "print(f\"\\nðŸ” Top-K Range: {config.TOP_K_MIN}-{config.TOP_K_MAX} (Default: {config.TOP_K_DEFAULT})\")\n",
                "\n",
                "print(f\"\\nðŸ“ Directories:\")\n",
                "print(f\"   Upload: {config.UPLOAD_FOLDER}\")\n",
                "print(f\"   ChromaDB: {config.CHROMA_PERSIST_DIR}\")\n",
                "\n",
                "print(\"\\nâœ… Configuration loaded!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“„ Section 3: PDF Parsing & Text Extraction\n",
                "\n",
                "### Ù‚Ø±Ø§Ø¡Ø© ÙˆØªØ­Ù„ÙŠÙ„ Ù…Ù„ÙØ§Øª PDF Ù„Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ©\n",
                "- ÙŠØ¯Ø¹Ù… `pdfplumber` Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¨Ø³ÙŠØ·Ø©\n",
                "- ÙŠØ¯Ø¹Ù… `PyMuPDF` Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©\n",
                "- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù‡ÙŠÙƒÙ„"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… PDF Parser class ready!\n",
                        "   Using: pdfplumber\n"
                    ]
                }
            ],
            "source": [
                "# ============================================\n",
                "# ðŸ“„ PDF PARSER CLASS\n",
                "# ============================================\n",
                "\n",
                "class PDFParser:\n",
                "    \"\"\"\n",
                "    PDF parsing with support for pdfplumber and PyMuPDF.\n",
                "    Extracts text while preserving structure for CV documents.\n",
                "    \"\"\"\n",
                "    \n",
                "    @staticmethod\n",
                "    def parse_with_pdfplumber(pdf_path: str) -> Dict[str, Any]:\n",
                "        \"\"\"\n",
                "        Parse PDF using pdfplumber (recommended for simple CVs).\n",
                "        \"\"\"\n",
                "        try:\n",
                "            text_content = []\n",
                "            metadata = {}\n",
                "            \n",
                "            with pdfplumber.open(pdf_path) as pdf:\n",
                "                metadata['pages'] = len(pdf.pages)\n",
                "                metadata['parser'] = 'pdfplumber'\n",
                "                \n",
                "                for i, page in enumerate(pdf.pages):\n",
                "                    page_text = page.extract_text()\n",
                "                    if page_text:\n",
                "                        text_content.append(page_text)\n",
                "            \n",
                "            full_text = \"\\n\\n\".join(text_content)\n",
                "            metadata['char_count'] = len(full_text)\n",
                "            metadata['word_count'] = len(full_text.split())\n",
                "            \n",
                "            return {\n",
                "                'success': True,\n",
                "                'text': full_text,\n",
                "                'metadata': metadata\n",
                "            }\n",
                "            \n",
                "        except Exception as e:\n",
                "            return {\n",
                "                'success': False,\n",
                "                'error': str(e),\n",
                "                'text': '',\n",
                "                'metadata': {}\n",
                "            }\n",
                "    \n",
                "    @staticmethod\n",
                "    def parse_with_pymupdf(pdf_path: str) -> Dict[str, Any]:\n",
                "        \"\"\"\n",
                "        Parse PDF using PyMuPDF (better for complex layouts).\n",
                "        \"\"\"\n",
                "        try:\n",
                "            import fitz  # PyMuPDF\n",
                "            \n",
                "            text_content = []\n",
                "            metadata = {}\n",
                "            \n",
                "            doc = fitz.open(pdf_path)\n",
                "            metadata['pages'] = len(doc)\n",
                "            metadata['parser'] = 'pymupdf'\n",
                "            \n",
                "            for page in doc:\n",
                "                text_content.append(page.get_text())\n",
                "            \n",
                "            doc.close()\n",
                "            \n",
                "            full_text = \"\\n\\n\".join(text_content)\n",
                "            metadata['char_count'] = len(full_text)\n",
                "            metadata['word_count'] = len(full_text.split())\n",
                "            \n",
                "            return {\n",
                "                'success': True,\n",
                "                'text': full_text,\n",
                "                'metadata': metadata\n",
                "            }\n",
                "            \n",
                "        except Exception as e:\n",
                "            return {\n",
                "                'success': False,\n",
                "                'error': str(e),\n",
                "                'text': '',\n",
                "                'metadata': {}\n",
                "            }\n",
                "    \n",
                "    @classmethod\n",
                "    def parse(cls, pdf_path: str, parser: str = \"pdfplumber\") -> Dict[str, Any]:\n",
                "        \"\"\"\n",
                "        Parse PDF using specified parser.\n",
                "        \"\"\"\n",
                "        if parser == \"pymupdf\":\n",
                "            return cls.parse_with_pymupdf(pdf_path)\n",
                "        return cls.parse_with_pdfplumber(pdf_path)\n",
                "\n",
                "# Test parser\n",
                "print(\"âœ… PDF Parser class ready!\")\n",
                "print(f\"   Using: {config.PDF_PARSER}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… Resume Manager initialized!\n"
                    ]
                }
            ],
            "source": [
                "# ============================================\n",
                "# ðŸ“ RESUME MANAGER - Handle PDF & CSV Data\n",
                "# ============================================\n",
                "\n",
                "class ResumeManager:\n",
                "    \"\"\"\n",
                "    Manages resume data from both CSV and PDF uploads.\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self):\n",
                "        self.resumes = []  # List of {id, text, source, category, metadata}\n",
                "        self.resume_count = 0\n",
                "    \n",
                "    def load_from_csv(self, csv_path: str, text_column: str = \"Resume\", \n",
                "                      category_column: str = \"Category\", limit: int = None) -> int:\n",
                "        \"\"\"\n",
                "        Load resumes from CSV file.\n",
                "        \"\"\"\n",
                "        df = pd.read_csv(csv_path)\n",
                "        \n",
                "        if limit:\n",
                "            df = df.head(limit)\n",
                "        \n",
                "        for idx, row in df.iterrows():\n",
                "            self.resumes.append({\n",
                "                'id': f\"csv_{self.resume_count}\",\n",
                "                'text': str(row[text_column]),\n",
                "                'source': 'csv',\n",
                "                'category': str(row.get(category_column, 'Unknown')),\n",
                "                'filename': csv_path,\n",
                "                'metadata': {'original_index': idx}\n",
                "            })\n",
                "            self.resume_count += 1\n",
                "        \n",
                "        return len(df)\n",
                "    \n",
                "    def add_pdf(self, pdf_path: str, category: str = \"Uploaded\") -> Dict:\n",
                "        \"\"\"\n",
                "        Add a single PDF resume.\n",
                "        \"\"\"\n",
                "        result = PDFParser.parse(pdf_path, config.PDF_PARSER)\n",
                "        \n",
                "        if result['success']:\n",
                "            resume_id = f\"pdf_{self.resume_count}\"\n",
                "            filename = os.path.basename(pdf_path)\n",
                "            \n",
                "            self.resumes.append({\n",
                "                'id': resume_id,\n",
                "                'text': result['text'],\n",
                "                'source': 'pdf',\n",
                "                'category': category,\n",
                "                'filename': filename,\n",
                "                'metadata': result['metadata']\n",
                "            })\n",
                "            self.resume_count += 1\n",
                "            \n",
                "            return {\n",
                "                'success': True,\n",
                "                'id': resume_id,\n",
                "                'filename': filename,\n",
                "                'pages': result['metadata'].get('pages', 0),\n",
                "                'words': result['metadata'].get('word_count', 0)\n",
                "            }\n",
                "        \n",
                "        return {'success': False, 'error': result.get('error', 'Unknown error')}\n",
                "    \n",
                "    def add_multiple_pdfs(self, pdf_folder: str, category: str = \"Uploaded\") -> List[Dict]:\n",
                "        \"\"\"\n",
                "        Add all PDFs from a folder.\n",
                "        \"\"\"\n",
                "        results = []\n",
                "        pdf_files = list(Path(pdf_folder).glob(\"*.pdf\"))\n",
                "        \n",
                "        for pdf_path in pdf_files:\n",
                "            result = self.add_pdf(str(pdf_path), category)\n",
                "            results.append(result)\n",
                "        \n",
                "        return results\n",
                "    \n",
                "    def get_all_resumes(self) -> List[Dict]:\n",
                "        \"\"\"Return all loaded resumes.\"\"\"\n",
                "        return self.resumes\n",
                "    \n",
                "    def get_dataframe(self) -> pd.DataFrame:\n",
                "        \"\"\"Return resumes as DataFrame.\"\"\"\n",
                "        return pd.DataFrame(self.resumes)\n",
                "    \n",
                "    def clear(self):\n",
                "        \"\"\"Clear all resumes.\"\"\"\n",
                "        self.resumes = []\n",
                "        self.resume_count = 0\n",
                "    \n",
                "    def summary(self) -> str:\n",
                "        \"\"\"Get summary of loaded resumes.\"\"\"\n",
                "        df = self.get_dataframe()\n",
                "        if df.empty:\n",
                "            return \"No resumes loaded.\"\n",
                "        \n",
                "        summary = f\"ðŸ“Š Total Resumes: {len(df)}\\n\"\n",
                "        summary += f\"   From CSV: {len(df[df['source'] == 'csv'])}\\n\"\n",
                "        summary += f\"   From PDF: {len(df[df['source'] == 'pdf'])}\\n\"\n",
                "        summary += f\"\\nðŸ“ Categories:\\n\"\n",
                "        for cat, count in df['category'].value_counts().items():\n",
                "            summary += f\"   - {cat}: {count}\\n\"\n",
                "        return summary\n",
                "\n",
                "# Initialize Resume Manager\n",
                "resume_manager = ResumeManager()\n",
                "print(\"âœ… Resume Manager initialized!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… Loaded 20 resumes from CSV for evaluation\n",
                        "ðŸ“Š Total Resumes: 20\n",
                        "   From CSV: 20\n",
                        "   From PDF: 0\n",
                        "\n",
                        "ðŸ“ Categories:\n",
                        "   - Data Science: 20\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# ============================================\n",
                "# ðŸ“Š LOAD CSV DATA (Optional - for evaluation)\n",
                "# ============================================\n",
                "\n",
                "# Check if CSV exists\n",
                "CSV_FILENAME = \"UpdatedResumeDataSet.csv\"\n",
                "\n",
                "if os.path.exists(CSV_FILENAME):\n",
                "    # Load sample data for evaluation\n",
                "    num_loaded = resume_manager.load_from_csv(CSV_FILENAME, limit=20)\n",
                "    print(f\"âœ… Loaded {num_loaded} resumes from CSV for evaluation\")\n",
                "    print(resume_manager.summary())\n",
                "else:\n",
                "    print(f\"âš ï¸ CSV file '{CSV_FILENAME}' not found.\")\n",
                "    print(\"   You can upload PDF resumes through the UI instead.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ”§ Section 4: Text Cleaning & Utilities"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ”§ Sample text cleaning:\n",
                        "Original: Skills * Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, ...\n",
                        "Cleaned: Skills  Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, J...\n"
                    ]
                }
            ],
            "source": [
                "def clean_text(text: str) -> str:\n",
                "    \"\"\"\n",
                "    Clean and normalize resume text.\n",
                "    \"\"\"\n",
                "    if not isinstance(text, str):\n",
                "        return \"\"\n",
                "    \n",
                "    # Remove extra whitespace\n",
                "    text = re.sub(r'\\s+', ' ', text)\n",
                "    \n",
                "    # Remove special characters but keep important punctuation\n",
                "    text = re.sub(r'[^\\w\\s.,;:()\\-@#&/]', '', text)\n",
                "    \n",
                "    # Fix spacing around punctuation\n",
                "    text = re.sub(r'\\s+([.,;:])', r'\\1', text)\n",
                "    \n",
                "    return text.strip()\n",
                "\n",
                "# Test cleaning\n",
                "if resume_manager.resumes:\n",
                "    sample_text = resume_manager.resumes[0]['text'][:200]\n",
                "    print(\"ðŸ”§ Sample text cleaning:\")\n",
                "    print(f\"Original: {sample_text[:100]}...\")\n",
                "    print(f\"Cleaned: {clean_text(sample_text)[:100]}...\")\n",
                "else:\n",
                "    print(\"âš ï¸ No resumes loaded yet. Load resumes first to test cleaning.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## âœ‚ï¸ Section 5: Chunking Strategies\n",
                "\n",
                "### 3 Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø§Ø®ØªÙŠØ§Ø± ÙˆØ§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©:\n",
                "\n",
                "| # | Strategy | Description | Best For |\n",
                "|---|----------|-------------|----------|\n",
                "| 1 | **Fixed-Length** | 300-400 chars with 10% overlap | Consistent chunk sizes |\n",
                "| 2 | **Sentence-Based** | Group sentences together | Natural text boundaries |\n",
                "| 3 | **Layout-Aware** | Split by headings/sections | Structured CVs |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… Chunking Strategies ready!\n",
                        "\n",
                        "ðŸ“Š Testing with sample resume...\n",
                        "\n",
                        "============================================================\n",
                        "\n",
                        "Fixed-Length (300-400 chars):\n",
                        "   Chunks: 14\n",
                        "   Avg Length: 369 chars\n",
                        "   Sample: Skills  Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, J...\n",
                        "\n",
                        "Sentence-Based:\n",
                        "   Chunks: 10\n",
                        "   Avg Length: 469 chars\n",
                        "   Sample: Skills  Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, J...\n",
                        "\n",
                        "Layout-Aware (Sections/Headings):\n",
                        "   Chunks: 1\n",
                        "   Avg Length: 4695 chars\n",
                        "   Sample: Skills  Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, J...\n"
                    ]
                }
            ],
            "source": [
                "# ============================================\n",
                "# âœ‚ï¸ CHUNKING STRATEGIES (3 Options)\n",
                "# ============================================\n",
                "\n",
                "class ChunkingStrategies:\n",
                "    \"\"\"\n",
                "    Three chunking strategies for CV/Resume documents.\n",
                "    All strategies use config settings for consistency.\n",
                "    \"\"\"\n",
                "    \n",
                "    # Section headers commonly found in CVs\n",
                "    SECTION_HEADERS = [\n",
                "        # English\n",
                "        \"skills\", \"technical skills\", \"skill\", \"programming\",\n",
                "        \"experience\", \"work experience\", \"professional experience\", \"employment\",\n",
                "        \"education\", \"academic\", \"qualification\", \"degree\",\n",
                "        \"projects\", \"personal projects\", \"achievements\", \"accomplishments\",\n",
                "        \"summary\", \"profile\", \"objective\", \"about me\", \"introduction\",\n",
                "        \"certifications\", \"certificates\", \"training\", \"courses\",\n",
                "        \"languages\", \"interests\", \"hobbies\", \"references\",\n",
                "        \"contact\", \"personal information\", \"details\"\n",
                "    ]\n",
                "    \n",
                "    @staticmethod\n",
                "    def clean_text(text: str) -> str:\n",
                "        \"\"\"Clean and normalize text.\"\"\"\n",
                "        if not isinstance(text, str):\n",
                "            return \"\"\n",
                "        text = re.sub(r'\\s+', ' ', text)\n",
                "        text = re.sub(r'[^\\w\\s.,;:()\\-@#&/+]', '', text)\n",
                "        text = re.sub(r'\\s+([.,;:])', r'\\1', text)\n",
                "        return text.strip()\n",
                "    \n",
                "    @classmethod\n",
                "    def fixed_length(cls, text: str, \n",
                "                     chunk_size: int = None, \n",
                "                     overlap_percent: int = None) -> List[Dict]:\n",
                "        \"\"\"\n",
                "        Strategy 1: Fixed-Length Chunking\n",
                "        - Chunk size: 300-400 characters\n",
                "        - Overlap: 10%\n",
                "        \"\"\"\n",
                "        chunk_size = chunk_size or config.CHUNK_SIZE\n",
                "        overlap_percent = overlap_percent or config.CHUNK_OVERLAP_PERCENT\n",
                "        overlap = int(chunk_size * overlap_percent / 100)\n",
                "        \n",
                "        text = cls.clean_text(text)\n",
                "        chunks = []\n",
                "        start = 0\n",
                "        chunk_idx = 0\n",
                "        \n",
                "        while start < len(text):\n",
                "            end = start + chunk_size\n",
                "            \n",
                "            # Try to break at word boundary\n",
                "            if end < len(text):\n",
                "                space_idx = text.rfind(' ', start + chunk_size - 50, end + 50)\n",
                "                if space_idx > start:\n",
                "                    end = space_idx\n",
                "            \n",
                "            chunk_text = text[start:end].strip()\n",
                "            if chunk_text:\n",
                "                chunks.append({\n",
                "                    'text': chunk_text,\n",
                "                    'start': start,\n",
                "                    'end': end,\n",
                "                    'index': chunk_idx,\n",
                "                    'strategy': 'fixed'\n",
                "                })\n",
                "                chunk_idx += 1\n",
                "            \n",
                "            start = end - overlap\n",
                "        \n",
                "        return chunks if chunks else [{'text': text[:chunk_size], 'start': 0, 'end': len(text), 'index': 0, 'strategy': 'fixed'}]\n",
                "    \n",
                "    @classmethod\n",
                "    def sentence_based(cls, text: str, \n",
                "                       max_sentences: int = None) -> List[Dict]:\n",
                "        \"\"\"\n",
                "        Strategy 2: Sentence-Based Chunking\n",
                "        - Groups sentences together\n",
                "        - Respects natural text boundaries\n",
                "        \"\"\"\n",
                "        max_sentences = max_sentences or config.MAX_SENTENCES_PER_CHUNK\n",
                "        \n",
                "        text = cls.clean_text(text)\n",
                "        \n",
                "        try:\n",
                "            sentences = sent_tokenize(text)\n",
                "        except:\n",
                "            sentences = re.split(r'[.!?]+', text)\n",
                "            sentences = [s.strip() for s in sentences if s.strip()]\n",
                "        \n",
                "        chunks = []\n",
                "        current_sentences = []\n",
                "        chunk_idx = 0\n",
                "        \n",
                "        for sentence in sentences:\n",
                "            sentence = sentence.strip()\n",
                "            if not sentence:\n",
                "                continue\n",
                "            \n",
                "            current_sentences.append(sentence)\n",
                "            \n",
                "            # Check if we should create a chunk\n",
                "            current_text = ' '.join(current_sentences)\n",
                "            \n",
                "            if len(current_sentences) >= max_sentences or len(current_text) >= config.CHUNK_SIZE_MAX:\n",
                "                chunks.append({\n",
                "                    'text': current_text,\n",
                "                    'start': 0,\n",
                "                    'end': len(current_text),\n",
                "                    'index': chunk_idx,\n",
                "                    'strategy': 'sentence',\n",
                "                    'sentence_count': len(current_sentences)\n",
                "                })\n",
                "                chunk_idx += 1\n",
                "                current_sentences = []\n",
                "        \n",
                "        # Add remaining sentences\n",
                "        if current_sentences:\n",
                "            chunks.append({\n",
                "                'text': ' '.join(current_sentences),\n",
                "                'start': 0,\n",
                "                'end': 0,\n",
                "                'index': chunk_idx,\n",
                "                'strategy': 'sentence',\n",
                "                'sentence_count': len(current_sentences)\n",
                "            })\n",
                "        \n",
                "        return chunks if chunks else [{'text': text[:config.CHUNK_SIZE], 'index': 0, 'strategy': 'sentence'}]\n",
                "    \n",
                "    @classmethod\n",
                "    def layout_aware(cls, text: str) -> List[Dict]:\n",
                "        \"\"\"\n",
                "        Strategy 3: Layout-Aware Chunking\n",
                "        - Splits by CV sections (Skills, Experience, Education, etc.)\n",
                "        - Preserves document structure\n",
                "        \"\"\"\n",
                "        text = cls.clean_text(text)\n",
                "        \n",
                "        # Split into lines/paragraphs\n",
                "        lines = re.split(r'[\\n\\r]+|(?<=[.!?])\\s+', text)\n",
                "        lines = [l.strip() for l in lines if l.strip()]\n",
                "        \n",
                "        def is_section_header(line: str) -> bool:\n",
                "            normalized = line.lower().strip()\n",
                "            # Check against known headers\n",
                "            for header in cls.SECTION_HEADERS:\n",
                "                if header in normalized and len(normalized) < 60:\n",
                "                    return True\n",
                "            # Check for common patterns\n",
                "            if re.match(r'^[A-Z][A-Z\\s]+:?\\s*$', line) and len(line) < 40:\n",
                "                return True\n",
                "            if re.match(r'^\\d+\\.\\s*[A-Z]', line):\n",
                "                return True\n",
                "            return False\n",
                "        \n",
                "        chunks = []\n",
                "        current_section = \"\"\n",
                "        current_content = []\n",
                "        chunk_idx = 0\n",
                "        \n",
                "        for line in lines:\n",
                "            if is_section_header(line):\n",
                "                # Save previous section\n",
                "                if current_content:\n",
                "                    section_text = f\"{current_section}: \" if current_section else \"\"\n",
                "                    section_text += ' '.join(current_content)\n",
                "                    \n",
                "                    # Split if too large\n",
                "                    if len(section_text) > config.CHUNK_SIZE_MAX:\n",
                "                        sub_chunks = cls.fixed_length(section_text)\n",
                "                        for sc in sub_chunks:\n",
                "                            sc['index'] = chunk_idx\n",
                "                            sc['strategy'] = 'layout'\n",
                "                            sc['section'] = current_section\n",
                "                            chunks.append(sc)\n",
                "                            chunk_idx += 1\n",
                "                    else:\n",
                "                        chunks.append({\n",
                "                            'text': section_text.strip(),\n",
                "                            'index': chunk_idx,\n",
                "                            'strategy': 'layout',\n",
                "                            'section': current_section\n",
                "                        })\n",
                "                        chunk_idx += 1\n",
                "                \n",
                "                current_section = line.strip()\n",
                "                current_content = []\n",
                "            else:\n",
                "                current_content.append(line)\n",
                "        \n",
                "        # Add final section\n",
                "        if current_content:\n",
                "            section_text = f\"{current_section}: \" if current_section else \"\"\n",
                "            section_text += ' '.join(current_content)\n",
                "            chunks.append({\n",
                "                'text': section_text.strip(),\n",
                "                'index': chunk_idx,\n",
                "                'strategy': 'layout',\n",
                "                'section': current_section\n",
                "            })\n",
                "        \n",
                "        return chunks if chunks else [{'text': text[:config.CHUNK_SIZE], 'index': 0, 'strategy': 'layout'}]\n",
                "    \n",
                "    @classmethod\n",
                "    def chunk(cls, text: str, strategy: str = \"fixed\") -> List[Dict]:\n",
                "        \"\"\"\n",
                "        Apply chunking strategy.\n",
                "        \n",
                "        Args:\n",
                "            text: Text to chunk\n",
                "            strategy: \"fixed\", \"sentence\", or \"layout\"\n",
                "        \"\"\"\n",
                "        if strategy == \"sentence\":\n",
                "            return cls.sentence_based(text)\n",
                "        elif strategy == \"layout\":\n",
                "            return cls.layout_aware(text)\n",
                "        else:\n",
                "            return cls.fixed_length(text)\n",
                "\n",
                "# Test chunking strategies\n",
                "print(\"âœ… Chunking Strategies ready!\")\n",
                "print(\"\\nðŸ“Š Testing with sample resume...\")\n",
                "\n",
                "if resume_manager.resumes:\n",
                "    test_text = resume_manager.resumes[0]['text']\n",
                "    \n",
                "    print(\"\\n\" + \"=\" * 60)\n",
                "    for strategy in [\"fixed\", \"sentence\", \"layout\"]:\n",
                "        chunks = ChunkingStrategies.chunk(test_text, strategy)\n",
                "        avg_len = sum(len(c['text']) for c in chunks) / len(chunks) if chunks else 0\n",
                "        print(f\"\\n{config.CHUNKING_STRATEGIES[strategy]}:\")\n",
                "        print(f\"   Chunks: {len(chunks)}\")\n",
                "        print(f\"   Avg Length: {avg_len:.0f} chars\")\n",
                "        print(f\"   Sample: {chunks[0]['text'][:100]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ”— Section 6: Embedding Models & Vector Database\n",
                "\n",
                "### 3 Ù†Ù…Ø§Ø°Ø¬ Embedding Ù…ØªØ§Ø­Ø©:\n",
                "| Model | Speed | Quality | Dimension |\n",
                "|-------|-------|---------|-----------|\n",
                "| MiniLM | âš¡ Fast | Good | 384 |\n",
                "| MPNet | ðŸ”¥ Medium | Best | 768 |\n",
                "| BGE | ðŸŽ¯ Medium | Strong Retrieval | 768 |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ”„ Loading model: MiniLM (Fast)...\n",
                        "âœ… Model loaded successfully!\n",
                        "\n",
                        "ðŸ“Š Available Models:\n",
                        "  â†’ MiniLM (Fast): Lightweight, fast inference. Good for quick experiments.\n",
                        "    MPNet (High Quality): Best quality for semantic similarity tasks.\n",
                        "    BGE (Strong Retrieval): Optimized for retrieval tasks. Strong semantic matching.\n",
                        "âœ… Model loaded successfully!\n",
                        "\n",
                        "ðŸ“Š Available Models:\n",
                        "  â†’ MiniLM (Fast): Lightweight, fast inference. Good for quick experiments.\n",
                        "    MPNet (High Quality): Best quality for semantic similarity tasks.\n",
                        "    BGE (Strong Retrieval): Optimized for retrieval tasks. Strong semantic matching.\n"
                    ]
                }
            ],
            "source": [
                "# ============================================\n",
                "# ðŸ”— EMBEDDING MODEL MANAGER\n",
                "# ============================================\n",
                "\n",
                "class EmbeddingManager:\n",
                "    \"\"\"\n",
                "    Manages multiple embedding models with dynamic switching.\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self):\n",
                "        self.models = {}\n",
                "        self.current_model_id = None\n",
                "        self.current_model = None\n",
                "    \n",
                "    def load_model(self, model_id: str) -> bool:\n",
                "        \"\"\"\n",
                "        Load an embedding model (cached for reuse).\n",
                "        \"\"\"\n",
                "        if model_id not in config.EMBEDDING_MODELS:\n",
                "            print(f\"âŒ Unknown model: {model_id}\")\n",
                "            return False\n",
                "        \n",
                "        if model_id in self.models:\n",
                "            self.current_model = self.models[model_id]\n",
                "            self.current_model_id = model_id\n",
                "            print(f\"âœ… Using cached model: {config.EMBEDDING_MODELS[model_id]['name']}\")\n",
                "            return True\n",
                "        \n",
                "        print(f\"ðŸ”„ Loading model: {config.EMBEDDING_MODELS[model_id]['name']}...\")\n",
                "        try:\n",
                "            self.models[model_id] = SentenceTransformer(model_id)\n",
                "            self.current_model = self.models[model_id]\n",
                "            self.current_model_id = model_id\n",
                "            print(f\"âœ… Model loaded successfully!\")\n",
                "            return True\n",
                "        except Exception as e:\n",
                "            print(f\"âŒ Error loading model: {e}\")\n",
                "            return False\n",
                "    \n",
                "    def encode(self, texts: List[str]) -> List[List[float]]:\n",
                "        \"\"\"\n",
                "        Generate embeddings for texts.\n",
                "        \"\"\"\n",
                "        if self.current_model is None:\n",
                "            self.load_model(config.DEFAULT_EMBEDDING_MODEL)\n",
                "        \n",
                "        return self.current_model.encode(texts).tolist()\n",
                "    \n",
                "    def get_model_info(self) -> Dict:\n",
                "        \"\"\"Get info about current model.\"\"\"\n",
                "        if self.current_model_id:\n",
                "            return config.EMBEDDING_MODELS[self.current_model_id]\n",
                "        return {}\n",
                "\n",
                "# Initialize Embedding Manager\n",
                "embedding_manager = EmbeddingManager()\n",
                "\n",
                "# Load default model\n",
                "embedding_manager.load_model(config.DEFAULT_EMBEDDING_MODEL)\n",
                "\n",
                "print(f\"\\nðŸ“Š Available Models:\")\n",
                "for model_id, info in config.EMBEDDING_MODELS.items():\n",
                "    marker = \"â†’\" if model_id == embedding_manager.current_model_id else \" \"\n",
                "    print(f\"  {marker} {info['name']}: {info['description']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… Vector Store (ChromaDB) initialized!\n"
                    ]
                }
            ],
            "source": [
                "# ============================================\n",
                "# ðŸ—„ï¸ VECTOR DATABASE (ChromaDB)\n",
                "# ============================================\n",
                "\n",
                "class VectorStore:\n",
                "    \"\"\"\n",
                "    ChromaDB vector store for resume retrieval.\n",
                "    Supports dynamic model and strategy switching.\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self):\n",
                "        self.client = chromadb.Client()\n",
                "        self.collections = {}  # {name: collection}\n",
                "        self.indexed_resumes = {}  # {collection_name: [resume_ids]}\n",
                "    \n",
                "    def create_collection(self, name: str, force_recreate: bool = False) -> chromadb.Collection:\n",
                "        \"\"\"\n",
                "        Create or get a collection.\n",
                "        \"\"\"\n",
                "        safe_name = re.sub(r'[^a-zA-Z0-9_-]', '_', name)[:50]\n",
                "        \n",
                "        if force_recreate and safe_name in self.collections:\n",
                "            try:\n",
                "                self.client.delete_collection(safe_name)\n",
                "            except:\n",
                "                pass\n",
                "            del self.collections[safe_name]\n",
                "        \n",
                "        if safe_name not in self.collections:\n",
                "            try:\n",
                "                self.client.delete_collection(safe_name)\n",
                "            except:\n",
                "                pass\n",
                "            self.collections[safe_name] = self.client.create_collection(name=safe_name)\n",
                "            self.indexed_resumes[safe_name] = []\n",
                "        \n",
                "        return self.collections[safe_name]\n",
                "    \n",
                "    def index_resumes(self, resumes: List[Dict], \n",
                "                      strategy: str = \"fixed\",\n",
                "                      collection_name: str = None,\n",
                "                      progress_callback = None) -> Dict:\n",
                "        \"\"\"\n",
                "        Index resumes into vector store.\n",
                "        \"\"\"\n",
                "        if not collection_name:\n",
                "            collection_name = f\"resumes_{strategy}_{embedding_manager.current_model_id.split('/')[-1]}\"\n",
                "        \n",
                "        collection = self.create_collection(collection_name, force_recreate=True)\n",
                "        \n",
                "        all_ids = []\n",
                "        all_docs = []\n",
                "        all_metas = []\n",
                "        \n",
                "        total = len(resumes)\n",
                "        \n",
                "        for i, resume in enumerate(resumes):\n",
                "            if progress_callback:\n",
                "                progress_callback(i / total, f\"Processing resume {i+1}/{total}\")\n",
                "            \n",
                "            # Chunk the resume\n",
                "            chunks = ChunkingStrategies.chunk(resume['text'], strategy)\n",
                "            \n",
                "            for j, chunk in enumerate(chunks):\n",
                "                chunk_id = f\"{resume['id']}_chunk_{j}\"\n",
                "                all_ids.append(chunk_id)\n",
                "                all_docs.append(chunk['text'])\n",
                "                all_metas.append({\n",
                "                    'resume_id': resume['id'],\n",
                "                    'category': resume.get('category', 'Unknown'),\n",
                "                    'filename': resume.get('filename', ''),\n",
                "                    'chunk_index': j,\n",
                "                    'strategy': strategy\n",
                "                })\n",
                "        \n",
                "        if progress_callback:\n",
                "            progress_callback(0.9, \"Generating embeddings...\")\n",
                "        \n",
                "        # Generate embeddings\n",
                "        all_embeddings = embedding_manager.encode(all_docs)\n",
                "        \n",
                "        if progress_callback:\n",
                "            progress_callback(0.95, \"Indexing into database...\")\n",
                "        \n",
                "        # Add to collection\n",
                "        collection.add(\n",
                "            ids=all_ids,\n",
                "            documents=all_docs,\n",
                "            metadatas=all_metas,\n",
                "            embeddings=all_embeddings\n",
                "        )\n",
                "        \n",
                "        self.indexed_resumes[collection_name] = [r['id'] for r in resumes]\n",
                "        \n",
                "        return {\n",
                "            'collection_name': collection_name,\n",
                "            'total_chunks': len(all_ids),\n",
                "            'total_resumes': len(resumes),\n",
                "            'strategy': strategy,\n",
                "            'model': embedding_manager.current_model_id\n",
                "        }\n",
                "    \n",
                "    def search(self, query: str, collection_name: str, \n",
                "               top_k: int = 3, \n",
                "               return_unique_resumes: bool = True) -> List[Dict]:\n",
                "        \"\"\"\n",
                "        Search for relevant resumes.\n",
                "        \"\"\"\n",
                "        if collection_name not in self.collections:\n",
                "            return []\n",
                "        \n",
                "        collection = self.collections[collection_name]\n",
                "        \n",
                "        # Generate query embedding\n",
                "        query_embedding = embedding_manager.encode([query])[0]\n",
                "        \n",
                "        # Search\n",
                "        results = collection.query(\n",
                "            query_embeddings=[query_embedding],\n",
                "            n_results=top_k * 3 if return_unique_resumes else top_k\n",
                "        )\n",
                "        \n",
                "        if not results['documents'] or not results['documents'][0]:\n",
                "            return []\n",
                "        \n",
                "        # Format results\n",
                "        formatted_results = []\n",
                "        seen_resumes = set()\n",
                "        \n",
                "        for i, (doc, meta, dist) in enumerate(zip(\n",
                "            results['documents'][0],\n",
                "            results['metadatas'][0],\n",
                "            results['distances'][0]\n",
                "        )):\n",
                "            resume_id = meta.get('resume_id', '')\n",
                "            \n",
                "            if return_unique_resumes:\n",
                "                if resume_id in seen_resumes:\n",
                "                    continue\n",
                "                seen_resumes.add(resume_id)\n",
                "            \n",
                "            similarity = 1 - dist  # Convert distance to similarity\n",
                "            \n",
                "            formatted_results.append({\n",
                "                'rank': len(formatted_results) + 1,\n",
                "                'resume_id': resume_id,\n",
                "                'category': meta.get('category', ''),\n",
                "                'filename': meta.get('filename', ''),\n",
                "                'chunk_text': doc,\n",
                "                'similarity': similarity,\n",
                "                'distance': dist\n",
                "            })\n",
                "            \n",
                "            if len(formatted_results) >= top_k:\n",
                "                break\n",
                "        \n",
                "        return formatted_results\n",
                "    \n",
                "    def get_collection_stats(self, collection_name: str) -> Dict:\n",
                "        \"\"\"Get statistics about a collection.\"\"\"\n",
                "        if collection_name not in self.collections:\n",
                "            return {}\n",
                "        \n",
                "        collection = self.collections[collection_name]\n",
                "        return {\n",
                "            'name': collection_name,\n",
                "            'total_chunks': collection.count(),\n",
                "            'total_resumes': len(self.indexed_resumes.get(collection_name, []))\n",
                "        }\n",
                "\n",
                "# Initialize Vector Store\n",
                "vector_store = VectorStore()\n",
                "print(\"âœ… Vector Store (ChromaDB) initialized!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“ Section 7: Ground Truth for Evaluation (Optional)\n",
                "\n",
                "### Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ù…Ø¹ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©\n",
                "> Ù‡Ø°Ø§ Ø§Ù„Ù‚Ø³Ù… Ø§Ø®ØªÙŠØ§Ø±ÙŠ - Ù„Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ ÙÙ‚Ø·"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ“‹ Sample resume content for Ground Truth preparation:\n",
                        "============================================================\n",
                        "\n",
                        "--- Resume 0 (Category: Data Science) ---\n",
                        "Skills * Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, JavaScript/JQuery. * Machine learning: Regression, SVM, NaÃƒÂ¯ve Bayes, KNN, Random Forest, Decision Trees, Boosting techniques, Cluster Analysis, Word Embedding, Sentiment Analysis, Natural Language processing, Dimensionality reduction, Topic Modelling (LDA, NMF), PCA & Neural Nets. * Database Visualizations: Mysql, SqlServer, Cassandra, Hbase, ElasticSearch D3.js, DC.js, Plotly, kibana, matplotlib\n",
                        "...\n",
                        "\n",
                        "--- Resume 1 (Category: Data Science) ---\n",
                        "Education Details \n",
                        "May 2013 to May 2017 B.E   UIT-RGPV\n",
                        "Data Scientist \n",
                        "\n",
                        "Data Scientist - Matelabs\n",
                        "Skill Details \n",
                        "Python- Exprience - Less than 1 year months\n",
                        "Statsmodels- Exprience - 12 months\n",
                        "AWS- Exprience - Less than 1 year months\n",
                        "Machine learning- Exprience - Less than 1 year months\n",
                        "Sklearn- Exprience - Less than 1 year months\n",
                        "Scipy- Exprience - Less than 1 year months\n",
                        "Keras- Exprience - Less than 1 year monthsCompany Details \n",
                        "company - Matelabs\n",
                        "description - ML Platform for bus\n",
                        "...\n",
                        "\n",
                        "--- Resume 2 (Category: Data Science) ---\n",
                        "Areas of Interest Deep Learning, Control System Design, Programming in-Python, Electric Machinery, Web Development, Analytics Technical Activities q Hindustan Aeronautics Limited, Bangalore - For 4 weeks under the guidance of Mr. Satish, Senior Engineer in the hangar of Mirage 2000 fighter aircraft Technical Skills Programming Matlab, Python and Java, LabView, Python WebFrameWork-Django, Flask, LTSPICE-intermediate Languages and and MIPOWER-intermediate, Github (GitBash), Jupyter Notebook, Xampp\n",
                        "...\n"
                    ]
                }
            ],
            "source": [
                "# First, let's analyze what information is in our resumes\n",
                "print(\"ðŸ“‹ Sample resume content for Ground Truth preparation:\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "if resume_manager.resumes:\n",
                "    for i in range(min(3, len(resume_manager.resumes))):\n",
                "        resume = resume_manager.resumes[i]\n",
                "        print(f\"\\n--- Resume {i} (Category: {resume['category']}) ---\")\n",
                "        print(resume['text'][:500])\n",
                "        print(\"...\")\n",
                "else:\n",
                "    print(\"âš ï¸ No resumes loaded. Please run the CSV loading cell first.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… Created 8 Ground Truth questions\n",
                        "\n",
                        "ðŸ“Š Question Types Distribution:\n",
                        "  - Direct Information: 2\n",
                        "  - Skills Query: 2\n",
                        "  - Experience Query: 2\n",
                        "  - Multi-step Query: 1\n",
                        "  - Comparison Query: 1\n"
                    ]
                }
            ],
            "source": [
                "# Define Ground Truth: Questions + Expected Relevant Resume IDs\n",
                "# Based on the actual content in our dataset\n",
                "\n",
                "GROUND_TRUTH = [\n",
                "    {\n",
                "        \"id\": \"Q1\",\n",
                "        \"type\": \"Direct Information\",\n",
                "        \"question\": \"Find resumes with Python programming experience\",\n",
                "        \"relevant_ids\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n",
                "        \"keywords\": [\"python\", \"programming\"]\n",
                "    },\n",
                "    {\n",
                "        \"id\": \"Q2\",\n",
                "        \"type\": \"Direct Information\",\n",
                "        \"question\": \"Who has experience with Machine Learning?\",\n",
                "        \"relevant_ids\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n",
                "        \"keywords\": [\"machine learning\", \"ml\", \"deep learning\"]\n",
                "    },\n",
                "    {\n",
                "        \"id\": \"Q3\",\n",
                "        \"type\": \"Skills Query\",\n",
                "        \"question\": \"Candidates with SQL database skills\",\n",
                "        \"relevant_ids\": [\"0\", \"2\", \"3\", \"4\", \"6\", \"8\"],\n",
                "        \"keywords\": [\"sql\", \"database\", \"mysql\"]\n",
                "    },\n",
                "    {\n",
                "        \"id\": \"Q4\",\n",
                "        \"type\": \"Experience Query\",\n",
                "        \"question\": \"Who worked at major tech companies or consulting firms?\",\n",
                "        \"relevant_ids\": [\"0\", \"3\", \"6\", \"8\"],\n",
                "        \"keywords\": [\"ernst\", \"young\", \"deloitte\", \"accenture\", \"wipro\", \"ibm\"]\n",
                "    },\n",
                "    {\n",
                "        \"id\": \"Q5\",\n",
                "        \"type\": \"Skills Query\",\n",
                "        \"question\": \"Find candidates with Data Visualization skills like Tableau\",\n",
                "        \"relevant_ids\": [\"0\", \"3\", \"5\", \"6\", \"8\"],\n",
                "        \"keywords\": [\"tableau\", \"visualization\", \"d3.js\", \"plotly\"]\n",
                "    },\n",
                "    {\n",
                "        \"id\": \"Q6\",\n",
                "        \"type\": \"Experience Query\",\n",
                "        \"question\": \"Candidates with NLP or Natural Language Processing experience\",\n",
                "        \"relevant_ids\": [\"0\", \"6\", \"7\", \"8\"],\n",
                "        \"keywords\": [\"nlp\", \"natural language\", \"text mining\", \"sentiment\"]\n",
                "    },\n",
                "    {\n",
                "        \"id\": \"Q7\",\n",
                "        \"type\": \"Multi-step Query\",\n",
                "        \"question\": \"Data Scientists with both Python and deep learning frameworks like TensorFlow or Keras\",\n",
                "        \"relevant_ids\": [\"1\", \"6\", \"7\"],\n",
                "        \"keywords\": [\"tensorflow\", \"keras\", \"deep learning\", \"neural network\"]\n",
                "    },\n",
                "    {\n",
                "        \"id\": \"Q8\",\n",
                "        \"type\": \"Comparison Query\",\n",
                "        \"question\": \"Who has cloud platform experience like AWS or GCP?\",\n",
                "        \"relevant_ids\": [\"1\", \"6\", \"8\"],\n",
                "        \"keywords\": [\"aws\", \"gcp\", \"google cloud\", \"azure\", \"cloud\"]\n",
                "    }\n",
                "]\n",
                "\n",
                "print(f\"âœ… Created {len(GROUND_TRUTH)} Ground Truth questions\")\n",
                "print(\"\\nðŸ“Š Question Types Distribution:\")\n",
                "types = {}\n",
                "for q in GROUND_TRUTH:\n",
                "    types[q['type']] = types.get(q['type'], 0) + 1\n",
                "for t, c in types.items():\n",
                "    print(f\"  - {t}: {c}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "ðŸ“‹ Ground Truth Questions:\n",
                        "+------+--------------------+-------------------------------------------------------+--------------+\n",
                        "| ID   | Type               | Question                                              |   # Relevant |\n",
                        "+======+====================+=======================================================+==============+\n",
                        "| Q1   | Direct Information | Find resumes with Python programming experience...    |           10 |\n",
                        "+------+--------------------+-------------------------------------------------------+--------------+\n",
                        "| Q2   | Direct Information | Who has experience with Machine Learning?...          |           10 |\n",
                        "+------+--------------------+-------------------------------------------------------+--------------+\n",
                        "| Q3   | Skills Query       | Candidates with SQL database skills...                |            6 |\n",
                        "+------+--------------------+-------------------------------------------------------+--------------+\n",
                        "| Q4   | Experience Query   | Who worked at major tech companies or consulting f... |            4 |\n",
                        "+------+--------------------+-------------------------------------------------------+--------------+\n",
                        "| Q5   | Skills Query       | Find candidates with Data Visualization skills lik... |            5 |\n",
                        "+------+--------------------+-------------------------------------------------------+--------------+\n",
                        "| Q6   | Experience Query   | Candidates with NLP or Natural Language Processing... |            4 |\n",
                        "+------+--------------------+-------------------------------------------------------+--------------+\n",
                        "| Q7   | Multi-step Query   | Data Scientists with both Python and deep learning... |            3 |\n",
                        "+------+--------------------+-------------------------------------------------------+--------------+\n",
                        "| Q8   | Comparison Query   | Who has cloud platform experience like AWS or GCP?... |            3 |\n",
                        "+------+--------------------+-------------------------------------------------------+--------------+\n"
                    ]
                }
            ],
            "source": [
                "# Display Ground Truth table\n",
                "gt_table = []\n",
                "for q in GROUND_TRUTH:\n",
                "    gt_table.append([\n",
                "        q['id'],\n",
                "        q['type'],\n",
                "        q['question'][:50] + \"...\",\n",
                "        len(q['relevant_ids'])\n",
                "    ])\n",
                "\n",
                "print(\"\\nðŸ“‹ Ground Truth Questions:\")\n",
                "print(tabulate(gt_table, \n",
                "               headers=['ID', 'Type', 'Question', '# Relevant'],\n",
                "               tablefmt='grid'))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“ˆ Section 8: Evaluation Metrics\n",
                "\n",
                "### Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…:\n",
                "| Metric | Description |\n",
                "|--------|-------------|\n",
                "| **Precision@K** | Ù†Ø³Ø¨Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØµØ­ÙŠØ­Ø© Ù…Ù† Ø£ÙˆÙ„ K |\n",
                "| **Recall@K** | Ù†Ø³Ø¨Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØµØ­ÙŠØ­Ø© Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹Ø© |\n",
                "| **MRR** | Ù…ØªÙˆØ³Ø· Ù…Ù‚Ù„ÙˆØ¨ ØªØ±ØªÙŠØ¨ Ø£ÙˆÙ„ Ù†ØªÙŠØ¬Ø© ØµØ­ÙŠØ­Ø© |\n",
                "| **MAP** | Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¯Ù‚Ø© |\n",
                "| **nDCG@K** | Normalized Discounted Cumulative Gain |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ§ª Testing metrics with sample data:\n",
                        "  Retrieved: ['0', '1', '5', '2', '3']\n",
                        "  Relevant:  {'3', '2', '4', '0'}\n",
                        "\n",
                        "  Precision@5: 0.600\n",
                        "  Recall@5:    0.750\n",
                        "  MRR:         1.000\n",
                        "  MAP:         0.525\n",
                        "  nDCG@5:      0.710\n"
                    ]
                }
            ],
            "source": [
                "class RetrievalMetrics:\n",
                "    \"\"\"\n",
                "    Evaluation metrics for retrieval systems.\n",
                "    \"\"\"\n",
                "    \n",
                "    @staticmethod\n",
                "    def precision_at_k(retrieved_ids: List[str], relevant_ids: set, k: int) -> float:\n",
                "        \"\"\"\n",
                "        Precision@K: What proportion of retrieved items are relevant?\n",
                "        \"\"\"\n",
                "        if k == 0:\n",
                "            return 0.0\n",
                "        retrieved_k = retrieved_ids[:k]\n",
                "        hits = sum(1 for doc_id in retrieved_k if doc_id in relevant_ids)\n",
                "        return hits / k\n",
                "    \n",
                "    @staticmethod\n",
                "    def recall_at_k(retrieved_ids: List[str], relevant_ids: set, k: int) -> float:\n",
                "        \"\"\"\n",
                "        Recall@K: What proportion of relevant items are retrieved?\n",
                "        \"\"\"\n",
                "        if not relevant_ids:\n",
                "            return 0.0\n",
                "        retrieved_k = retrieved_ids[:k]\n",
                "        hits = sum(1 for doc_id in retrieved_k if doc_id in relevant_ids)\n",
                "        return hits / len(relevant_ids)\n",
                "    \n",
                "    @staticmethod\n",
                "    def mrr(retrieved_ids: List[str], relevant_ids: set) -> float:\n",
                "        \"\"\"\n",
                "        Mean Reciprocal Rank: 1/rank of first relevant result.\n",
                "        \"\"\"\n",
                "        for i, doc_id in enumerate(retrieved_ids, start=1):\n",
                "            if doc_id in relevant_ids:\n",
                "                return 1.0 / i\n",
                "        return 0.0\n",
                "    \n",
                "    @staticmethod\n",
                "    def average_precision(retrieved_ids: List[str], relevant_ids: set) -> float:\n",
                "        \"\"\"\n",
                "        Average Precision for a single query.\n",
                "        \"\"\"\n",
                "        if not relevant_ids:\n",
                "            return 0.0\n",
                "        \n",
                "        ap_sum = 0.0\n",
                "        hits = 0\n",
                "        \n",
                "        for i, doc_id in enumerate(retrieved_ids, start=1):\n",
                "            if doc_id in relevant_ids:\n",
                "                hits += 1\n",
                "                ap_sum += hits / i\n",
                "        \n",
                "        if hits == 0:\n",
                "            return 0.0\n",
                "        \n",
                "        return ap_sum / len(relevant_ids)\n",
                "    \n",
                "    @staticmethod\n",
                "    def dcg_at_k(retrieved_ids: List[str], relevant_ids: set, k: int) -> float:\n",
                "        \"\"\"\n",
                "        Discounted Cumulative Gain at K.\n",
                "        \"\"\"\n",
                "        dcg = 0.0\n",
                "        for i, doc_id in enumerate(retrieved_ids[:k], start=1):\n",
                "            rel = 1.0 if doc_id in relevant_ids else 0.0\n",
                "            if rel > 0:\n",
                "                dcg += rel / math.log2(i + 1)\n",
                "        return dcg\n",
                "    \n",
                "    @classmethod\n",
                "    def ndcg_at_k(cls, retrieved_ids: List[str], relevant_ids: set, k: int) -> float:\n",
                "        \"\"\"\n",
                "        Normalized DCG at K.\n",
                "        \"\"\"\n",
                "        if not relevant_ids:\n",
                "            return 0.0\n",
                "        \n",
                "        dcg = cls.dcg_at_k(retrieved_ids, relevant_ids, k)\n",
                "        \n",
                "        # Ideal ranking: all relevant docs first\n",
                "        ideal_order = list(relevant_ids)[:k]\n",
                "        idcg = cls.dcg_at_k(ideal_order, relevant_ids, k)\n",
                "        \n",
                "        if idcg == 0.0:\n",
                "            return 0.0\n",
                "        \n",
                "        return dcg / idcg\n",
                "\n",
                "# Test metrics\n",
                "test_retrieved = [\"0\", \"1\", \"5\", \"2\", \"3\"]\n",
                "test_relevant = {\"0\", \"2\", \"3\", \"4\"}\n",
                "\n",
                "print(\"ðŸ§ª Testing metrics with sample data:\")\n",
                "print(f\"  Retrieved: {test_retrieved}\")\n",
                "print(f\"  Relevant:  {test_relevant}\")\n",
                "print(f\"\\n  Precision@5: {RetrievalMetrics.precision_at_k(test_retrieved, test_relevant, 5):.3f}\")\n",
                "print(f\"  Recall@5:    {RetrievalMetrics.recall_at_k(test_retrieved, test_relevant, 5):.3f}\")\n",
                "print(f\"  MRR:         {RetrievalMetrics.mrr(test_retrieved, test_relevant):.3f}\")\n",
                "print(f\"  MAP:         {RetrievalMetrics.average_precision(test_retrieved, test_relevant):.3f}\")\n",
                "print(f\"  nDCG@5:      {RetrievalMetrics.ndcg_at_k(test_retrieved, test_relevant, 5):.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ”„ Section 8: Evaluation Pipeline\n",
                "\n",
                "### Running evaluation for each chunking strategy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… Evaluation pipeline ready!\n"
                    ]
                }
            ],
            "source": [
                "def evaluate_strategy(strategy_name: str, collection: chromadb.Collection, \n",
                "                      ground_truth: List[Dict], k: int = 10) -> Dict[str, float]:\n",
                "    \"\"\"\n",
                "    Evaluate a chunking strategy using Ground Truth questions.\n",
                "    Returns average metrics across all queries.\n",
                "    \"\"\"\n",
                "    all_precision = []\n",
                "    all_recall = []\n",
                "    all_mrr = []\n",
                "    all_map = []\n",
                "    all_ndcg = []\n",
                "    \n",
                "    query_results = []  # Store detailed results\n",
                "    \n",
                "    for gt in ground_truth:\n",
                "        query = gt['question']\n",
                "        relevant_ids = set(gt['relevant_ids'])\n",
                "        \n",
                "        # Query the collection\n",
                "        results = collection.query(\n",
                "            query_texts=[query],\n",
                "            n_results=k * 3  # Get more to dedupe\n",
                "        )\n",
                "        \n",
                "        # Extract unique resume IDs from chunk results\n",
                "        retrieved_resume_ids = []\n",
                "        seen_ids = set()\n",
                "        \n",
                "        if results['metadatas'] and results['metadatas'][0]:\n",
                "            for meta in results['metadatas'][0]:\n",
                "                resume_id = meta.get('resume_id', '')\n",
                "                if resume_id and resume_id not in seen_ids:\n",
                "                    seen_ids.add(resume_id)\n",
                "                    retrieved_resume_ids.append(resume_id)\n",
                "                    if len(retrieved_resume_ids) >= k:\n",
                "                        break\n",
                "        \n",
                "        # Calculate metrics\n",
                "        precision = RetrievalMetrics.precision_at_k(retrieved_resume_ids, relevant_ids, k)\n",
                "        recall = RetrievalMetrics.recall_at_k(retrieved_resume_ids, relevant_ids, k)\n",
                "        mrr = RetrievalMetrics.mrr(retrieved_resume_ids, relevant_ids)\n",
                "        map_score = RetrievalMetrics.average_precision(retrieved_resume_ids, relevant_ids)\n",
                "        ndcg = RetrievalMetrics.ndcg_at_k(retrieved_resume_ids, relevant_ids, k)\n",
                "        \n",
                "        all_precision.append(precision)\n",
                "        all_recall.append(recall)\n",
                "        all_mrr.append(mrr)\n",
                "        all_map.append(map_score)\n",
                "        all_ndcg.append(ndcg)\n",
                "        \n",
                "        query_results.append({\n",
                "            'query_id': gt['id'],\n",
                "            'query_type': gt['type'],\n",
                "            'retrieved': retrieved_resume_ids[:5],\n",
                "            'precision': precision,\n",
                "            'recall': recall,\n",
                "            'mrr': mrr\n",
                "        })\n",
                "    \n",
                "    return {\n",
                "        'Precision@K': np.mean(all_precision),\n",
                "        'Recall@K': np.mean(all_recall),\n",
                "        'MRR': np.mean(all_mrr),\n",
                "        'MAP': np.mean(all_map),\n",
                "        'nDCG@K': np.mean(all_ndcg),\n",
                "        'query_results': query_results\n",
                "    }\n",
                "\n",
                "print(\"âœ… Evaluation pipeline ready!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ”„ Running evaluation for each chunking strategy...\n",
                        "============================================================\n",
                        "\n",
                        "ðŸ“Š Evaluating: Fixed-Length\n",
                        "   Creating collection and indexing...\n",
                        "   Collection size: 186 chunks\n",
                        "   Running queries...\n",
                        "   Collection size: 186 chunks\n",
                        "   Running queries...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\abrah\\.cache\\chroma\\onnx_models\\all-MiniLM-L6-v2\\onnx.tar.gz: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79.3M/79.3M [00:36<00:00, 2.29MiB/s]\n",
                        "\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "   âœ… Precision@10: 0.000\n",
                        "   âœ… Recall@10: 0.000\n",
                        "   âœ… MRR: 0.000\n",
                        "\n",
                        "ðŸ“Š Evaluating: Sentence-Based\n",
                        "   Creating collection and indexing...\n",
                        "   Collection size: 124 chunks\n",
                        "   Running queries...\n",
                        "   Collection size: 124 chunks\n",
                        "   Running queries...\n",
                        "   âœ… Precision@10: 0.000\n",
                        "   âœ… Recall@10: 0.000\n",
                        "   âœ… MRR: 0.000\n",
                        "\n",
                        "ðŸ“Š Evaluating: Layout-Aware\n",
                        "   Creating collection and indexing...\n",
                        "   âœ… Precision@10: 0.000\n",
                        "   âœ… Recall@10: 0.000\n",
                        "   âœ… MRR: 0.000\n",
                        "\n",
                        "ðŸ“Š Evaluating: Layout-Aware\n",
                        "   Creating collection and indexing...\n",
                        "   Collection size: 68 chunks\n",
                        "   Running queries...\n",
                        "   Collection size: 68 chunks\n",
                        "   Running queries...\n",
                        "   âœ… Precision@10: 0.000\n",
                        "   âœ… Recall@10: 0.000\n",
                        "   âœ… MRR: 0.000\n",
                        "\n",
                        "============================================================\n",
                        "âœ… Evaluation complete!\n",
                        "   âœ… Precision@10: 0.000\n",
                        "   âœ… Recall@10: 0.000\n",
                        "   âœ… MRR: 0.000\n",
                        "\n",
                        "============================================================\n",
                        "âœ… Evaluation complete!\n"
                    ]
                }
            ],
            "source": [
                "# Run evaluation for all chunking strategies\n",
                "K = 10  # Number of results to retrieve\n",
                "\n",
                "# Map strategy names to the keys used in config\n",
                "strategies = {\n",
                "    \"Fixed-Length\": \"fixed\",\n",
                "    \"Sentence-Based\": \"sentence\",\n",
                "    \"Layout-Aware\": \"layout\"\n",
                "}\n",
                "\n",
                "evaluation_results = {}\n",
                "\n",
                "print(\"ðŸ”„ Running evaluation for each chunking strategy...\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "if not resume_manager.resumes:\n",
                "    print(\"âŒ No resumes loaded. Please run the CSV loading cell first.\")\n",
                "else:\n",
                "    for strategy_name, strategy_key in strategies.items():\n",
                "        print(f\"\\nðŸ“Š Evaluating: {strategy_name}\")\n",
                "        \n",
                "        # Index resumes with this strategy\n",
                "        print(f\"   Creating collection and indexing...\")\n",
                "        result = vector_store.index_resumes(\n",
                "            resume_manager.resumes,\n",
                "            strategy=strategy_key\n",
                "        )\n",
                "        collection = vector_store.collections[result['collection_name']]\n",
                "        print(f\"   Collection size: {collection.count()} chunks\")\n",
                "        \n",
                "        # Evaluate\n",
                "        print(f\"   Running queries...\")\n",
                "        results = evaluate_strategy(strategy_name, collection, GROUND_TRUTH, k=K)\n",
                "        evaluation_results[strategy_name] = results\n",
                "        \n",
                "        print(f\"   âœ… Precision@{K}: {results['Precision@K']:.3f}\")\n",
                "        print(f\"   âœ… Recall@{K}: {results['Recall@K']:.3f}\")\n",
                "        print(f\"   âœ… MRR: {results['MRR']:.3f}\")\n",
                "\n",
                "    print(\"\\n\" + \"=\" * 60)\n",
                "    print(\"âœ… Evaluation complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“Š Section 9: Results Comparison Table\n",
                "\n",
                "### Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "================================================================================\n",
                        "ðŸ“Š CHUNKING STRATEGY COMPARISON TABLE\n",
                        "================================================================================\n",
                        "+----------------+----------------+-------------+-------+-------+-----------+\n",
                        "| Strategy       |  Precision@10  |  Recall@10  |  MRR  |  MAP  |  nDCG@10  |\n",
                        "+================+================+=============+=======+=======+===========+\n",
                        "| Fixed-Length   |       0        |      0      |   0   |   0   |     0     |\n",
                        "+----------------+----------------+-------------+-------+-------+-----------+\n",
                        "| Sentence-Based |       0        |      0      |   0   |   0   |     0     |\n",
                        "+----------------+----------------+-------------+-------+-------+-----------+\n",
                        "| Layout-Aware   |       0        |      0      |   0   |   0   |     0     |\n",
                        "+----------------+----------------+-------------+-------+-------+-----------+\n",
                        "================================================================================\n"
                    ]
                }
            ],
            "source": [
                "# Create comparison table\n",
                "comparison_data = []\n",
                "\n",
                "for strategy_name, results in evaluation_results.items():\n",
                "    comparison_data.append([\n",
                "        strategy_name,\n",
                "        f\"{results['Precision@K']:.4f}\",\n",
                "        f\"{results['Recall@K']:.4f}\",\n",
                "        f\"{results['MRR']:.4f}\",\n",
                "        f\"{results['MAP']:.4f}\",\n",
                "        f\"{results['nDCG@K']:.4f}\"\n",
                "    ])\n",
                "\n",
                "print(\"\\n\" + \"=\" * 80)\n",
                "print(\"ðŸ“Š CHUNKING STRATEGY COMPARISON TABLE\")\n",
                "print(\"=\" * 80)\n",
                "print(tabulate(\n",
                "    comparison_data,\n",
                "    headers=['Strategy', f'Precision@{K}', f'Recall@{K}', 'MRR', 'MAP', f'nDCG@{K}'],\n",
                "    tablefmt='grid',\n",
                "    numalign='center'\n",
                "))\n",
                "print(\"=\" * 80)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "ðŸ“Š Results DataFrame:\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Precision@10</th>\n",
                            "      <th>Recall@10</th>\n",
                            "      <th>MRR</th>\n",
                            "      <th>MAP</th>\n",
                            "      <th>nDCG@10</th>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>Strategy</th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>Fixed-Length</th>\n",
                            "      <td>0.0000</td>\n",
                            "      <td>0.0000</td>\n",
                            "      <td>0.0000</td>\n",
                            "      <td>0.0000</td>\n",
                            "      <td>0.0000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>Sentence-Based</th>\n",
                            "      <td>0.0000</td>\n",
                            "      <td>0.0000</td>\n",
                            "      <td>0.0000</td>\n",
                            "      <td>0.0000</td>\n",
                            "      <td>0.0000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>Layout-Aware</th>\n",
                            "      <td>0.0000</td>\n",
                            "      <td>0.0000</td>\n",
                            "      <td>0.0000</td>\n",
                            "      <td>0.0000</td>\n",
                            "      <td>0.0000</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "               Precision@10 Recall@10     MRR     MAP nDCG@10\n",
                            "Strategy                                                     \n",
                            "Fixed-Length         0.0000    0.0000  0.0000  0.0000  0.0000\n",
                            "Sentence-Based       0.0000    0.0000  0.0000  0.0000  0.0000\n",
                            "Layout-Aware         0.0000    0.0000  0.0000  0.0000  0.0000"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Create a pandas DataFrame for better visualization\n",
                "results_df = pd.DataFrame(comparison_data, \n",
                "                          columns=['Strategy', f'Precision@{K}', f'Recall@{K}', 'MRR', 'MAP', f'nDCG@{K}'])\n",
                "results_df = results_df.set_index('Strategy')\n",
                "\n",
                "# Convert to numeric for analysis\n",
                "results_df_numeric = results_df.astype(float)\n",
                "\n",
                "print(\"\\nðŸ“Š Results DataFrame:\")\n",
                "display(results_df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "============================================================\n",
                        "ðŸ† FINAL RESULTS\n",
                        "============================================================\n",
                        "\n",
                        "ðŸ“ˆ Overall Scores (Average of all metrics):\n",
                        "  ðŸ¥‡ Fixed-Length: 0.0000\n",
                        "     Sentence-Based: 0.0000\n",
                        "     Layout-Aware: 0.0000\n",
                        "\n",
                        "ðŸŽ¯ Best Chunking Strategy: Fixed-Length\n",
                        "   Overall Score: 0.0000\n",
                        "\n",
                        "ðŸ“Š Best Strategy per Metric:\n",
                        "  - Precision@10: Fixed-Length (0.0000)\n",
                        "  - Recall@10: Fixed-Length (0.0000)\n",
                        "  - MRR: Fixed-Length (0.0000)\n",
                        "  - MAP: Fixed-Length (0.0000)\n",
                        "  - nDCG@10: Fixed-Length (0.0000)\n"
                    ]
                }
            ],
            "source": [
                "# Determine the best strategy\n",
                "# Calculate overall score (average of all metrics)\n",
                "overall_scores = results_df_numeric.mean(axis=1)\n",
                "best_strategy = overall_scores.idxmax()\n",
                "best_score = overall_scores.max()\n",
                "\n",
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"ðŸ† FINAL RESULTS\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "print(\"\\nðŸ“ˆ Overall Scores (Average of all metrics):\")\n",
                "for strategy, score in overall_scores.sort_values(ascending=False).items():\n",
                "    marker = \"ðŸ¥‡\" if strategy == best_strategy else \"  \"\n",
                "    print(f\"  {marker} {strategy}: {score:.4f}\")\n",
                "\n",
                "print(f\"\\nðŸŽ¯ Best Chunking Strategy: {best_strategy}\")\n",
                "print(f\"   Overall Score: {best_score:.4f}\")\n",
                "\n",
                "# Best per metric\n",
                "print(\"\\nðŸ“Š Best Strategy per Metric:\")\n",
                "for col in results_df_numeric.columns:\n",
                "    best_for_metric = results_df_numeric[col].idxmax()\n",
                "    best_value = results_df_numeric[col].max()\n",
                "    print(f\"  - {col}: {best_for_metric} ({best_value:.4f})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“‹ Section 10: Detailed Query Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "ðŸ“‹ Detailed Query Results for Best Strategy: Fixed-Length\n",
                        "================================================================================\n",
                        "+---------+--------------------+------------------------------+-------------+----------+-------+\n",
                        "| Query   | Type               | Top 3 Retrieved              |   Precision |   Recall |   MRR |\n",
                        "+=========+====================+==============================+=============+==========+=======+\n",
                        "| Q1      | Direct Information | ['csv_2', 'csv_12', 'csv_6'] |           0 |        0 |     0 |\n",
                        "+---------+--------------------+------------------------------+-------------+----------+-------+\n",
                        "| Q2      | Direct Information | ['csv_6', 'csv_16', 'csv_7'] |           0 |        0 |     0 |\n",
                        "+---------+--------------------+------------------------------+-------------+----------+-------+\n",
                        "| Q3      | Skills Query       | ['csv_8', 'csv_18', 'csv_3'] |           0 |        0 |     0 |\n",
                        "+---------+--------------------+------------------------------+-------------+----------+-------+\n",
                        "| Q4      | Experience Query   | ['csv_3', 'csv_13', 'csv_6'] |           0 |        0 |     0 |\n",
                        "+---------+--------------------+------------------------------+-------------+----------+-------+\n",
                        "| Q5      | Skills Query       | ['csv_6', 'csv_16', 'csv_0'] |           0 |        0 |     0 |\n",
                        "+---------+--------------------+------------------------------+-------------+----------+-------+\n",
                        "| Q6      | Experience Query   | ['csv_7', 'csv_17', 'csv_0'] |           0 |        0 |     0 |\n",
                        "+---------+--------------------+------------------------------+-------------+----------+-------+\n",
                        "| Q7      | Multi-step Query   | ['csv_7', 'csv_17', 'csv_0'] |           0 |        0 |     0 |\n",
                        "+---------+--------------------+------------------------------+-------------+----------+-------+\n",
                        "| Q8      | Comparison Query   | ['csv_7', 'csv_17', 'csv_9'] |           0 |        0 |     0 |\n",
                        "+---------+--------------------+------------------------------+-------------+----------+-------+\n"
                    ]
                }
            ],
            "source": [
                "# Show detailed results for best strategy\n",
                "print(f\"\\nðŸ“‹ Detailed Query Results for Best Strategy: {best_strategy}\")\n",
                "print(\"=\" * 80)\n",
                "\n",
                "detailed_results = []\n",
                "for qr in evaluation_results[best_strategy]['query_results']:\n",
                "    detailed_results.append([\n",
                "        qr['query_id'],\n",
                "        qr['query_type'],\n",
                "        str(qr['retrieved'][:3]),\n",
                "        f\"{qr['precision']:.3f}\",\n",
                "        f\"{qr['recall']:.3f}\",\n",
                "        f\"{qr['mrr']:.3f}\"\n",
                "    ])\n",
                "\n",
                "print(tabulate(\n",
                "    detailed_results,\n",
                "    headers=['Query', 'Type', 'Top 3 Retrieved', 'Precision', 'Recall', 'MRR'],\n",
                "    tablefmt='grid'\n",
                "))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "ðŸ“Š Ground Truth vs Retrieved Results Comparison\n",
                        "================================================================================\n",
                        "\n",
                        "Q1: Find resumes with Python programming experience...\n",
                        "  Expected:  ['0', '1', '2', '3', '4']\n",
                        "  Retrieved: ['csv_2', 'csv_12', 'csv_6', 'csv_16', 'csv_8']\n",
                        "  Precision: 0.000 | Recall: 0.000 | MRR: 0.000\n",
                        "\n",
                        "Q2: Who has experience with Machine Learning?...\n",
                        "  Expected:  ['0', '1', '2', '3', '4']\n",
                        "  Retrieved: ['csv_6', 'csv_16', 'csv_7', 'csv_17', 'csv_8']\n",
                        "  Precision: 0.000 | Recall: 0.000 | MRR: 0.000\n",
                        "\n",
                        "Q3: Candidates with SQL database skills...\n",
                        "  Expected:  ['0', '2', '3', '4', '6']\n",
                        "  Retrieved: ['csv_8', 'csv_18', 'csv_3', 'csv_13', 'csv_6']\n",
                        "  Precision: 0.000 | Recall: 0.000 | MRR: 0.000\n",
                        "\n",
                        "Q4: Who worked at major tech companies or consulting firms?...\n",
                        "  Expected:  ['0', '3', '6', '8']\n",
                        "  Retrieved: ['csv_3', 'csv_13', 'csv_6', 'csv_16', 'csv_9']\n",
                        "  Precision: 0.000 | Recall: 0.000 | MRR: 0.000\n",
                        "\n",
                        "Q5: Find candidates with Data Visualization skills like Tableau...\n",
                        "  Expected:  ['0', '3', '5', '6', '8']\n",
                        "  Retrieved: ['csv_6', 'csv_16', 'csv_0', 'csv_10', 'csv_3']\n",
                        "  Precision: 0.000 | Recall: 0.000 | MRR: 0.000\n",
                        "\n",
                        "Q6: Candidates with NLP or Natural Language Processing experienc...\n",
                        "  Expected:  ['0', '6', '7', '8']\n",
                        "  Retrieved: ['csv_7', 'csv_17', 'csv_0', 'csv_10', 'csv_8']\n",
                        "  Precision: 0.000 | Recall: 0.000 | MRR: 0.000\n",
                        "\n",
                        "Q7: Data Scientists with both Python and deep learning framework...\n",
                        "  Expected:  ['1', '6', '7']\n",
                        "  Retrieved: ['csv_7', 'csv_17', 'csv_0', 'csv_10', 'csv_2']\n",
                        "  Precision: 0.000 | Recall: 0.000 | MRR: 0.000\n",
                        "\n",
                        "Q8: Who has cloud platform experience like AWS or GCP?...\n",
                        "  Expected:  ['1', '6', '8']\n",
                        "  Retrieved: ['csv_7', 'csv_17', 'csv_9', 'csv_19', 'csv_0']\n",
                        "  Precision: 0.000 | Recall: 0.000 | MRR: 0.000\n"
                    ]
                }
            ],
            "source": [
                "# Compare Ground Truth vs Retrieved for each question\n",
                "print(\"\\nðŸ“Š Ground Truth vs Retrieved Results Comparison\")\n",
                "print(\"=\" * 80)\n",
                "\n",
                "for i, gt in enumerate(GROUND_TRUTH):\n",
                "    qr = evaluation_results[best_strategy]['query_results'][i]\n",
                "    print(f\"\\n{gt['id']}: {gt['question'][:60]}...\")\n",
                "    print(f\"  Expected:  {gt['relevant_ids'][:5]}\")\n",
                "    print(f\"  Retrieved: {qr['retrieved'][:5]}\")\n",
                "    print(f\"  Precision: {qr['precision']:.3f} | Recall: {qr['recall']:.3f} | MRR: {qr['mrr']:.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ–¥ï¸ Section 11: Interactive Gradio UI\n",
                "\n",
                "### ÙˆØ§Ø¬Ù‡Ø© ØªÙØ§Ø¹Ù„ÙŠØ© Ù…ØªÙƒØ§Ù…Ù„Ø© ØªØ´Ù…Ù„:\n",
                "- ðŸ“„ Ø±ÙØ¹ Ù…Ù„ÙØ§Øª PDF\n",
                "- ðŸ”¤ Ø§Ø®ØªÙŠØ§Ø± Ù†Ù…ÙˆØ°Ø¬ Embedding\n",
                "- âœ‚ï¸ Ø§Ø®ØªÙŠØ§Ø± Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Chunking\n",
                "- ðŸ” Ø§Ù„Ø¨Ø­Ø« Ù…Ø¹ Ø§Ù„ØªØ­ÙƒÙ… Ø¨Ù€ Top-K\n",
                "- ðŸ“Š Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØ§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… Gradio UI ready!\n"
                    ]
                }
            ],
            "source": [
                "# ============================================\n",
                "# ðŸ–¥ï¸ GRADIO INTERACTIVE UI\n",
                "# ============================================\n",
                "\n",
                "import gradio as gr\n",
                "\n",
                "# Global state\n",
                "current_collection = None\n",
                "\n",
                "def upload_pdfs(files, category):\n",
                "    \"\"\"Handle PDF file uploads.\"\"\"\n",
                "    global current_collection\n",
                "    \n",
                "    if not files:\n",
                "        return \"âŒ No files uploaded\", resume_manager.summary()\n",
                "    \n",
                "    results = []\n",
                "    for file in files:\n",
                "        result = resume_manager.add_pdf(file.name, category or \"Uploaded\")\n",
                "        if result['success']:\n",
                "            results.append(f\"âœ… {result['filename']} ({result['pages']} pages, {result['words']} words)\")\n",
                "        else:\n",
                "            results.append(f\"âŒ {os.path.basename(file.name)}: {result.get('error', 'Unknown error')}\")\n",
                "    \n",
                "    current_collection = None  # Reset to force re-indexing\n",
                "    \n",
                "    return \"\\n\".join(results), resume_manager.summary()\n",
                "\n",
                "def change_embedding_model(model_name):\n",
                "    \"\"\"Switch embedding model.\"\"\"\n",
                "    global current_collection\n",
                "    \n",
                "    # Find model ID from name\n",
                "    model_id = None\n",
                "    for mid, info in config.EMBEDDING_MODELS.items():\n",
                "        if info['name'] == model_name:\n",
                "            model_id = mid\n",
                "            break\n",
                "    \n",
                "    if model_id:\n",
                "        success = embedding_manager.load_model(model_id)\n",
                "        current_collection = None  # Reset to force re-indexing\n",
                "        if success:\n",
                "            return f\"âœ… Switched to {model_name}\"\n",
                "        return f\"âŒ Failed to load {model_name}\"\n",
                "    return \"âŒ Unknown model\"\n",
                "\n",
                "def index_resumes(strategy_name, progress=gr.Progress()):\n",
                "    \"\"\"Index all resumes with selected strategy.\"\"\"\n",
                "    global current_collection\n",
                "    \n",
                "    if not resume_manager.resumes:\n",
                "        return \"âŒ No resumes loaded. Please upload PDFs or load CSV first.\", \"\"\n",
                "    \n",
                "    # Find strategy key from name\n",
                "    strategy_key = None\n",
                "    for key, name in config.CHUNKING_STRATEGIES.items():\n",
                "        if name == strategy_name:\n",
                "            strategy_key = key\n",
                "            break\n",
                "    \n",
                "    if not strategy_key:\n",
                "        strategy_key = \"fixed\"\n",
                "    \n",
                "    progress(0, desc=\"Starting indexing...\")\n",
                "    \n",
                "    result = vector_store.index_resumes(\n",
                "        resume_manager.resumes,\n",
                "        strategy=strategy_key,\n",
                "        progress_callback=lambda p, msg: progress(p, desc=msg)\n",
                "    )\n",
                "    \n",
                "    current_collection = result['collection_name']\n",
                "    \n",
                "    stats = f\"\"\"\n",
                "âœ… **Indexing Complete!**\n",
                "\n",
                "ðŸ“Š **Statistics:**\n",
                "- Total Resumes: {result['total_resumes']}\n",
                "- Total Chunks: {result['total_chunks']}\n",
                "- Strategy: {strategy_name}\n",
                "- Model: {config.EMBEDDING_MODELS[result['model']]['name']}\n",
                "\"\"\"\n",
                "    return stats, current_collection\n",
                "\n",
                "def search_resumes(query, top_k):\n",
                "    \"\"\"Search for relevant resumes using the current collection.\"\"\"\n",
                "    global current_collection\n",
                "    \n",
                "    if not query.strip():\n",
                "        return \"âŒ Please enter a search query.\"\n",
                "    \n",
                "    # Auto-index if no collection exists\n",
                "    if not current_collection:\n",
                "        if not resume_manager.resumes:\n",
                "            return \"âŒ No resumes loaded. Please upload PDFs or load CSV first.\"\n",
                "        # Auto-index with default strategy\n",
                "        result = vector_store.index_resumes(\n",
                "            resume_manager.resumes,\n",
                "            strategy=\"fixed\"\n",
                "        )\n",
                "        current_collection = result['collection_name']\n",
                "    \n",
                "    results = vector_store.search(query, current_collection, top_k=int(top_k))\n",
                "    \n",
                "    if not results:\n",
                "        return \"No results found.\"\n",
                "    \n",
                "    output = f\"## ðŸ” Search Results for: '{query}'\\n\\n\"\n",
                "    output += f\"**Top-K:** {int(top_k)} | **Total Resumes:** {len(resume_manager.resumes)}\\n\\n\"\n",
                "    output += \"---\\n\\n\"\n",
                "    \n",
                "    for r in results:\n",
                "        similarity_bar = \"ðŸŸ¢\" * int(r['similarity'] * 10) + \"âšª\" * (10 - int(r['similarity'] * 10))\n",
                "        \n",
                "        output += f\"### #{r['rank']} - {r['filename'] or r['resume_id']}\\n\"\n",
                "        output += f\"**Category:** {r['category']} | **Similarity:** {r['similarity']:.3f} {similarity_bar}\\n\\n\"\n",
                "        output += f\"**Relevant Text:**\\n\"\n",
                "        output += f\"> {r['chunk_text'][:500]}{'...' if len(r['chunk_text']) > 500 else ''}\\n\\n\"\n",
                "        output += \"---\\n\\n\"\n",
                "    \n",
                "    return output\n",
                "\n",
                "def compare_strategies(query, top_k, progress=gr.Progress()):\n",
                "    \"\"\"Compare all chunking strategies.\"\"\"\n",
                "    if not query.strip():\n",
                "        return \"âŒ Please enter a search query.\"\n",
                "    \n",
                "    if not resume_manager.resumes:\n",
                "        return \"âŒ No resumes loaded.\"\n",
                "    \n",
                "    comparison = \"## ðŸ“Š Strategy Comparison\\n\\n\"\n",
                "    comparison += f\"**Query:** {query}\\n\\n\"\n",
                "    \n",
                "    for i, (strategy_key, strategy_name) in enumerate(config.CHUNKING_STRATEGIES.items()):\n",
                "        progress((i + 1) / len(config.CHUNKING_STRATEGIES), desc=f\"Testing {strategy_name}...\")\n",
                "        \n",
                "        # Index with this strategy\n",
                "        result = vector_store.index_resumes(\n",
                "            resume_manager.resumes,\n",
                "            strategy=strategy_key\n",
                "        )\n",
                "        \n",
                "        # Search\n",
                "        results = vector_store.search(query, result['collection_name'], top_k=int(top_k))\n",
                "        \n",
                "        comparison += f\"### {strategy_name}\\n\"\n",
                "        comparison += f\"- Chunks created: {result['total_chunks']}\\n\"\n",
                "        comparison += f\"- Top result: {results[0]['filename'] if results else 'N/A'}\\n\"\n",
                "        comparison += f\"- Top similarity: {results[0]['similarity']:.3f if results else 0}\\n\\n\"\n",
                "        \n",
                "        if results:\n",
                "            comparison += \"**Top 3 Results:**\\n\"\n",
                "            for r in results[:3]:\n",
                "                comparison += f\"  - {r['filename'] or r['resume_id']}: {r['similarity']:.3f}\\n\"\n",
                "        \n",
                "        comparison += \"\\n---\\n\\n\"\n",
                "    \n",
                "    return comparison\n",
                "\n",
                "# Build UI\n",
                "with gr.Blocks(title=\"ðŸ“„ Resume RAG System\", theme=gr.themes.Soft()) as demo:\n",
                "    gr.Markdown(\"\"\"\n",
                "    # ðŸ“„ Resume Retrieval System (RAG)\n",
                "    \n",
                "    Ù†Ø¸Ø§Ù… Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… RAG - Ø¨Ø¯ÙˆÙ† LLM\n",
                "    \n",
                "    ### ðŸ“‹ Instructions:\n",
                "    1. Upload PDF resumes or use existing CSV data\n",
                "    2. Select embedding model and chunking strategy\n",
                "    3. Click \"Index Resumes\" to process\n",
                "    4. Search using natural language queries\n",
                "    \"\"\")\n",
                "    \n",
                "    with gr.Tabs():\n",
                "        # Tab 1: Upload & Configure\n",
                "        with gr.Tab(\"ðŸ“¤ Upload & Configure\"):\n",
                "            with gr.Row():\n",
                "                with gr.Column(scale=2):\n",
                "                    file_upload = gr.File(\n",
                "                        label=\"ðŸ“„ Upload PDF Resumes\",\n",
                "                        file_count=\"multiple\",\n",
                "                        file_types=[\".pdf\"],\n",
                "                        type=\"filepath\"\n",
                "                    )\n",
                "                    category_input = gr.Textbox(\n",
                "                        label=\"Category (optional)\",\n",
                "                        placeholder=\"e.g., Data Science, Engineering\",\n",
                "                        value=\"Uploaded\"\n",
                "                    )\n",
                "                    upload_btn = gr.Button(\"ðŸ“¤ Upload Files\", variant=\"primary\")\n",
                "                    upload_status = gr.Textbox(label=\"Upload Status\", lines=3)\n",
                "                \n",
                "                with gr.Column(scale=1):\n",
                "                    resume_summary = gr.Textbox(\n",
                "                        label=\"ðŸ“Š Resume Summary\",\n",
                "                        lines=10,\n",
                "                        value=resume_manager.summary()\n",
                "                    )\n",
                "            \n",
                "            upload_btn.click(\n",
                "                upload_pdfs,\n",
                "                inputs=[file_upload, category_input],\n",
                "                outputs=[upload_status, resume_summary]\n",
                "            )\n",
                "        \n",
                "        # Tab 2: Model & Strategy\n",
                "        with gr.Tab(\"âš™ï¸ Model & Strategy\"):\n",
                "            with gr.Row():\n",
                "                with gr.Column():\n",
                "                    model_dropdown = gr.Dropdown(\n",
                "                        label=\"ðŸ”¤ Embedding Model\",\n",
                "                        choices=[info['name'] for info in config.EMBEDDING_MODELS.values()],\n",
                "                        value=config.EMBEDDING_MODELS[config.DEFAULT_EMBEDDING_MODEL]['name']\n",
                "                    )\n",
                "                    model_status = gr.Textbox(label=\"Model Status\")\n",
                "                    model_dropdown.change(\n",
                "                        change_embedding_model,\n",
                "                        inputs=[model_dropdown],\n",
                "                        outputs=[model_status]\n",
                "                    )\n",
                "                \n",
                "                with gr.Column():\n",
                "                    strategy_dropdown = gr.Dropdown(\n",
                "                        label=\"âœ‚ï¸ Chunking Strategy\",\n",
                "                        choices=list(config.CHUNKING_STRATEGIES.values()),\n",
                "                        value=config.CHUNKING_STRATEGIES[\"fixed\"]\n",
                "                    )\n",
                "            \n",
                "            with gr.Row():\n",
                "                index_btn = gr.Button(\"ðŸ”„ Index Resumes\", variant=\"primary\", scale=2)\n",
                "                collection_display = gr.Textbox(label=\"Collection Name\", scale=1)\n",
                "            \n",
                "            index_status = gr.Markdown()\n",
                "            \n",
                "            index_btn.click(\n",
                "                index_resumes,\n",
                "                inputs=[strategy_dropdown],\n",
                "                outputs=[index_status, collection_display]\n",
                "            )\n",
                "        \n",
                "        # Tab 3: Search\n",
                "        with gr.Tab(\"ðŸ” Search\"):\n",
                "            with gr.Row():\n",
                "                query_input = gr.Textbox(\n",
                "                    label=\"ðŸ” Search Query\",\n",
                "                    placeholder=\"e.g., 'Python machine learning experience'\",\n",
                "                    lines=2,\n",
                "                    scale=3\n",
                "                )\n",
                "                top_k_slider = gr.Slider(\n",
                "                    minimum=config.TOP_K_MIN,\n",
                "                    maximum=config.TOP_K_MAX,\n",
                "                    value=config.TOP_K_DEFAULT,\n",
                "                    step=1,\n",
                "                    label=\"Top-K Results\",\n",
                "                    scale=1\n",
                "                )\n",
                "            \n",
                "            search_btn = gr.Button(\"ðŸ” Search\", variant=\"primary\")\n",
                "            search_results = gr.Markdown()\n",
                "            \n",
                "            search_btn.click(\n",
                "                search_resumes,\n",
                "                inputs=[query_input, top_k_slider],\n",
                "                outputs=[search_results]\n",
                "            )\n",
                "            \n",
                "            gr.Markdown(\"### ðŸ’¡ Example Queries:\")\n",
                "            gr.Examples(\n",
                "                examples=[\n",
                "                    [\"Python programming experience\", 3],\n",
                "                    [\"Machine learning and data analysis\", 5],\n",
                "                    [\"SQL database skills\", 3],\n",
                "                    [\"Cloud experience AWS or GCP\", 3],\n",
                "                    [\"Natural language processing NLP\", 3]\n",
                "                ],\n",
                "                inputs=[query_input, top_k_slider]\n",
                "            )\n",
                "        \n",
                "        # Tab 4: Compare Strategies\n",
                "        with gr.Tab(\"ðŸ“Š Compare Strategies\"):\n",
                "            gr.Markdown(\"### Compare all 3 chunking strategies on the same query\")\n",
                "            \n",
                "            compare_query = gr.Textbox(\n",
                "                label=\"Query for Comparison\",\n",
                "                placeholder=\"Enter query to test all strategies...\"\n",
                "            )\n",
                "            compare_k = gr.Slider(\n",
                "                minimum=1, maximum=5, value=3, step=1,\n",
                "                label=\"Top-K for Comparison\"\n",
                "            )\n",
                "            compare_btn = gr.Button(\"ðŸ“Š Compare All Strategies\", variant=\"primary\")\n",
                "            compare_results = gr.Markdown()\n",
                "            \n",
                "            compare_btn.click(\n",
                "                compare_strategies,\n",
                "                inputs=[compare_query, compare_k],\n",
                "                outputs=[compare_results]\n",
                "            )\n",
                "\n",
                "print(\"âœ… Gradio UI ready!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "* Running on local URL:  http://127.0.0.1:7861\n",
                        "* To create a public link, set `share=True` in `launch()`.\n",
                        "* To create a public link, set `share=True` in `launch()`.\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/plain": []
                    },
                    "execution_count": 31,
                    "metadata": {},
                    "output_type": "execute_result"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Traceback (most recent call last):\n",
                        "  File \"c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\gradio\\queueing.py\", line 763, in process_events\n",
                        "    response = await route_utils.call_process_api(\n",
                        "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\gradio\\route_utils.py\", line 354, in call_process_api\n",
                        "    output = await app.get_blocks().process_api(\n",
                        "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\gradio\\blocks.py\", line 2125, in process_api\n",
                        "    result = await self.call_function(\n",
                        "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\gradio\\blocks.py\", line 1607, in call_function\n",
                        "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
                        "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\anyio\\to_thread.py\", line 61, in run_sync\n",
                        "    return await get_async_backend().run_sync_in_worker_thread(\n",
                        "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2525, in run_sync_in_worker_thread\n",
                        "    return await future\n",
                        "           ^^^^^^^^^^^^\n",
                        "  File \"c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 986, in run\n",
                        "    result = context.run(func, *args)\n",
                        "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\gradio\\utils.py\", line 1066, in wrapper\n",
                        "    response = f(*args, **kwargs)\n",
                        "               ^^^^^^^^^^^^^^^^^^\n",
                        "  File \"C:\\Users\\abrah\\AppData\\Local\\Temp\\ipykernel_4632\\2384850696.py\", line 150, in compare_strategies\n",
                        "    comparison += f\"- Top similarity: {results[0]['similarity']:.3f if results else 0}\\n\\n\"\n",
                        "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "ValueError: Invalid format specifier '.3f if results else 0' for object of type 'float'\n",
                        "Traceback (most recent call last):\n",
                        "  File \"c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\gradio\\queueing.py\", line 763, in process_events\n",
                        "    response = await route_utils.call_process_api(\n",
                        "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\gradio\\route_utils.py\", line 354, in call_process_api\n",
                        "    output = await app.get_blocks().process_api(\n",
                        "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\gradio\\blocks.py\", line 2125, in process_api\n",
                        "    result = await self.call_function(\n",
                        "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\gradio\\blocks.py\", line 1607, in call_function\n",
                        "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
                        "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\anyio\\to_thread.py\", line 61, in run_sync\n",
                        "    return await get_async_backend().run_sync_in_worker_thread(\n",
                        "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2525, in run_sync_in_worker_thread\n",
                        "    return await future\n",
                        "           ^^^^^^^^^^^^\n",
                        "  File \"c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 986, in run\n",
                        "    result = context.run(func, *args)\n",
                        "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\gradio\\utils.py\", line 1066, in wrapper\n",
                        "    response = f(*args, **kwargs)\n",
                        "               ^^^^^^^^^^^^^^^^^^\n",
                        "  File \"C:\\Users\\abrah\\AppData\\Local\\Temp\\ipykernel_4632\\2384850696.py\", line 150, in compare_strategies\n",
                        "    comparison += f\"- Top similarity: {results[0]['similarity']:.3f if results else 0}\\n\\n\"\n",
                        "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "ValueError: Invalid format specifier '.3f if results else 0' for object of type 'float'\n",
                        "Traceback (most recent call last):\n",
                        "  File \"c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\gradio\\queueing.py\", line 763, in process_events\n",
                        "    response = await route_utils.call_process_api(\n",
                        "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\gradio\\route_utils.py\", line 354, in call_process_api\n",
                        "    output = await app.get_blocks().process_api(\n",
                        "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\gradio\\blocks.py\", line 2125, in process_api\n",
                        "    result = await self.call_function(\n",
                        "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\gradio\\blocks.py\", line 1607, in call_function\n",
                        "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
                        "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\anyio\\to_thread.py\", line 61, in run_sync\n",
                        "    return await get_async_backend().run_sync_in_worker_thread(\n",
                        "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2525, in run_sync_in_worker_thread\n",
                        "    return await future\n",
                        "           ^^^^^^^^^^^^\n",
                        "  File \"c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 986, in run\n",
                        "    result = context.run(func, *args)\n",
                        "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"c:\\Users\\abrah\\anaconda3\\envs\\rag\\Lib\\site-packages\\gradio\\utils.py\", line 1066, in wrapper\n",
                        "    response = f(*args, **kwargs)\n",
                        "               ^^^^^^^^^^^^^^^^^^\n",
                        "  File \"C:\\Users\\abrah\\AppData\\Local\\Temp\\ipykernel_4632\\2384850696.py\", line 150, in compare_strategies\n",
                        "    comparison += f\"- Top similarity: {results[0]['similarity']:.3f if results else 0}\\n\\n\"\n",
                        "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "ValueError: Invalid format specifier '.3f if results else 0' for object of type 'float'\n"
                    ]
                }
            ],
            "source": [
                "# ============================================\n",
                "# ðŸš€ LAUNCH GRADIO UI\n",
                "# ============================================\n",
                "\n",
                "# Launch the interface (auto-select available port)\n",
                "demo.launch(\n",
                "    share=False,  # Set to True if you want a public link\n",
                "    server_name=\"127.0.0.1\",\n",
                "    server_port=None,  # Auto-select available port\n",
                "    inbrowser=True  # Open browser automatically\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“ Section 12: Summary & How to Use\n",
                "\n",
                "### ÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:\n",
                "\n",
                "#### 1ï¸âƒ£ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ù„Ø§ÙŠØ§ Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨\n",
                "- Ø´ØºÙ‘Ù„ ÙƒÙ„ Ø§Ù„Ø®Ù„Ø§ÙŠØ§ Ù…Ù† Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ù„Ù„Ù†Ù‡Ø§ÙŠØ©\n",
                "\n",
                "#### 2ï¸âƒ£ Ø±ÙØ¹ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ©\n",
                "- Ø§Ø°Ù‡Ø¨ Ù„ØªØ§Ø¨ \"Upload & Configure\"\n",
                "- Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§Øª PDF\n",
                "- Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† CSV\n",
                "\n",
                "#### 3ï¸âƒ£ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n",
                "- Ø§Ø®ØªØ± Embedding Model\n",
                "- Ø§Ø®ØªØ± Chunking Strategy\n",
                "- Ø§Ø¶ØºØ· \"Index Resumes\"\n",
                "\n",
                "#### 4ï¸âƒ£ Ø§Ù„Ø¨Ø­Ø«\n",
                "- Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ (Ù…Ø«Ù„: \"Ù…Ù† Ø¹Ù†Ø¯Ù‡ PythonØŸ\")\n",
                "- Ø­Ø¯Ø¯ Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (Top-K)\n",
                "- Ø§Ø¶ØºØ· Search\n",
                "\n",
                "#### 5ï¸âƒ£ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©\n",
                "- Ø§Ø³ØªØ®Ø¯Ù… ØªØ§Ø¨ \"Compare Strategies\"\n",
                "- Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# ðŸ“Š SYSTEM SUMMARY\n",
                "# ============================================\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"ðŸ“„ RESUME RAG SYSTEM - SUMMARY\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "print(f\"\"\"\n",
                "ðŸŽ¯ FEATURES:\n",
                "âœ… PDF Upload & Parsing (pdfplumber)\n",
                "âœ… 3 Embedding Models (MiniLM, MPNet, BGE)\n",
                "âœ… 3 Chunking Strategies (Fixed, Sentence, Layout)\n",
                "âœ… Top-K Control (1-10, default=3)\n",
                "âœ… Strategy Comparison Tool\n",
                "âœ… Interactive Gradio UI\n",
                "\n",
                "ðŸ“¦ CONFIGURATION:\n",
                "â€¢ Chunk Size: {config.CHUNK_SIZE_MIN}-{config.CHUNK_SIZE_MAX} chars\n",
                "â€¢ Overlap: {config.CHUNK_OVERLAP_PERCENT}%\n",
                "â€¢ Default Model: {config.DEFAULT_EMBEDDING_MODEL}\n",
                "â€¢ Default Top-K: {config.TOP_K_DEFAULT}\n",
                "\n",
                "ðŸ“ DATA:\n",
                "{resume_manager.summary()}\n",
                "\n",
                "ðŸš€ TO START:\n",
                "1. Run all cells in order\n",
                "2. Upload PDFs or use CSV data\n",
                "3. Select model & strategy\n",
                "4. Index resumes\n",
                "5. Search!\n",
                "\n",
                "âœ… SYSTEM READY!\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## ðŸ“Œ END OF NOTEBOOK\n",
                "\n",
                "### Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ÙÙ†ÙØ°Ø© âœ…\n",
                "\n",
                "| Feature | Status |\n",
                "|---------|--------|\n",
                "| PDF Upload & Parsing | âœ… |\n",
                "| 3 Embedding Models | âœ… |\n",
                "| 3 Chunking Strategies | âœ… |\n",
                "| Top-K Control (1-10) | âœ… |\n",
                "| Interactive Gradio UI | âœ… |\n",
                "| Strategy Comparison | âœ… |\n",
                "| Evaluation Metrics | âœ… |\n",
                "\n",
                "### ðŸ”§ Technical Stack:\n",
                "- **PDF Parser**: pdfplumber (with PyMuPDF option)\n",
                "- **Embeddings**: SentenceTransformer (Free, Local)\n",
                "- **Vector DB**: ChromaDB (In-memory)\n",
                "- **UI**: Gradio\n",
                "- **Environment**: VS Code + Conda Python 3.11"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "rag",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
